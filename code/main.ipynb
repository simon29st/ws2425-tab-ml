{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\\n%pip install openml\\n%pip install numpy\\n%pip install pandas\\n# cf. https://pytorch.org/get-started/locally/\\n#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\\n%pip install -U scikit-learn\\n%pip install scipy\\n%pip install -U pymoo\\n%pip list'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\n",
    "%pip install openml\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# cf. https://pytorch.org/get-started/locally/\n",
    "#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\n",
    "%pip install -U scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -U pymoo\n",
    "%pip list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(359955, 'blood-transfusion-service-center', '2', (748, 5)), (10093, 'banknote-authentication', '2', (1372, 5)), (146820, 'wilt', '2', (4839, 6)), (168350, 'phoneme', '2', (5404, 6)), (37, 'diabetes', 'tested_positive', (768, 9)), (146819, 'climate-model-simulation-crashes', '1', (540, 19)), (359972, 'sylvine', '1', (5124, 21)), (3913, 'kc2', 'yes', (522, 22)), (3918, 'pc1', True, (1109, 22)), (359962, 'kc1', True, (2109, 22)), (3904, 'jm1', True, (10885, 22)), (167120, 'numerai28.6', '1', (96320, 22)), (9946, 'wdbc', '2', (569, 31)), (359975, 'Satellite', 'Anomaly', (5100, 37)), (3903, 'pc3', True, (1563, 38)), (43, 'spambase', '1', (4601, 58)), (190137, 'ozone-level-8hr', '2', (2534, 73)), (190392, 'madeline', '1', (3140, 260)), (190410, 'philippine', '1', (5832, 309)), (189922, 'gina', '1', (3153, 971))]\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']\n",
    "\n",
    "zipped = list(zip(oml_task_ids, oml_datasets, positive_classes))\n",
    "zipped = sorted(zipped, key=lambda item: (item[1].get_data()[0].shape[1], item[1].get_data()[0].shape[0]))  # order ascending by # of features, tiebreaker is # of samples\n",
    "print([(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance 1: [(359955, 'blood-transfusion-service-center', '2', (748, 5)), (146819, 'climate-model-simulation-crashes', '1', (540, 19)), (3904, 'jm1', True, (10885, 22)), (43, 'spambase', '1', (4601, 58))]\n",
      "instance 2: [(10093, 'banknote-authentication', '2', (1372, 5)), (359972, 'sylvine', '1', (5124, 21)), (167120, 'numerai28.6', '1', (96320, 22)), (190137, 'ozone-level-8hr', '2', (2534, 73))]\n",
      "instance 3: [(146820, 'wilt', '2', (4839, 6)), (3913, 'kc2', 'yes', (522, 22)), (9946, 'wdbc', '2', (569, 31)), (190392, 'madeline', '1', (3140, 260))]\n",
      "instance 4: [(168350, 'phoneme', '2', (5404, 6)), (3918, 'pc1', True, (1109, 22)), (359975, 'Satellite', 'Anomaly', (5100, 37)), (190410, 'philippine', '1', (5832, 309))]\n",
      "instance 5: [(37, 'diabetes', 'tested_positive', (768, 9)), (359962, 'kc1', True, (2109, 22)), (3903, 'pc3', True, (1563, 38)), (189922, 'gina', '1', (3153, 971))]\n",
      "20\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "zipped_instance_1 = zipped[::5]\n",
    "zipped_instance_2 = zipped[1::5]\n",
    "zipped_instance_3 = zipped[2::5]\n",
    "zipped_instance_4 = zipped[3::5]\n",
    "zipped_instance_5 = zipped[4::5]\n",
    "\n",
    "print('instance 1:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_1])\n",
    "print('instance 2:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_2])\n",
    "print('instance 3:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_3])\n",
    "print('instance 4:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_4])\n",
    "print('instance 5:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_5])\n",
    "\n",
    "# verify that all 20 are included\n",
    "zipped_instances_union = set.union(\n",
    "    set(ds.name for _, ds, _ in zipped_instance_1),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_2),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_3),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_4),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_5)\n",
    ")\n",
    "print(len(zipped_instances_union))\n",
    "print(zipped_instances_union == set(ds.name for _, ds, _ in zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset banknote-authentication\n",
      "Dataset banknote-authentication\n",
      "Starting init population\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m logging\u001b[39m.\u001b[39minfo(msg)\n\u001b[0;32m     24\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mexport\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[1;32m---> 26\u001b[0m eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     27\u001b[0m     oml_dataset\u001b[39m=\u001b[39;49moml_dataset,\n\u001b[0;32m     28\u001b[0m     class_positive\u001b[39m=\u001b[39;49mclass_positive,\n\u001b[0;32m     29\u001b[0m     hps\u001b[39m=\u001b[39;49mhps,\n\u001b[0;32m     30\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     31\u001b[0m     min_epochs\u001b[39m=\u001b[39;49mmin_epochs,\n\u001b[0;32m     32\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[0;32m     33\u001b[0m     secs_per_fold\u001b[39m=\u001b[39;49msecs_per_fold,\n\u001b[0;32m     34\u001b[0m     secs_total\u001b[39m=\u001b[39;49msecs_total,\n\u001b[0;32m     35\u001b[0m     file_path\u001b[39m=\u001b[39;49mfile_path\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[39m#eagga.load_population(0)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m pareto_front \u001b[39m=\u001b[39m eagga\u001b[39m.\u001b[39mrun_eagga()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:589\u001b[0m, in \u001b[0;36mEAGGA.__init__\u001b[1;34m(self, oml_dataset, class_positive, hps, batch_size, min_epochs, patience, secs_per_fold, secs_total, file_path)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path \u001b[39m=\u001b[39m file_path  \u001b[39m# if not None -> autosave each generation, else do nothing\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmonotonicity_clipper \u001b[39m=\u001b[39m WeightClipper(\u001b[39m0\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# enforce monotonicity by clipping weights to [0, infty) after each epoch (in def train)\u001b[39;00m\n\u001b[1;32m--> 589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_population()\n\u001b[0;32m    590\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m    591\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:606\u001b[0m, in \u001b[0;36mEAGGA.init_population\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    604\u001b[0m population_features_excluded \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(all_features) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(features_included)) \u001b[39mfor\u001b[39;00m features_included \u001b[39min\u001b[39;00m population_features_included]\n\u001b[0;32m    605\u001b[0m population_interactions \u001b[39m=\u001b[39m [GroupStructure\u001b[39m.\u001b[39mdetector_interactions(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_train_val, features_included, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_column) \u001b[39mfor\u001b[39;00m features_included \u001b[39min\u001b[39;00m population_features_included]\n\u001b[1;32m--> 606\u001b[0m population_monotonicity_constraints \u001b[39m=\u001b[39m [GroupStructure\u001b[39m.\u001b[39;49mdetector_monotonicity(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_train_val, groups_without_monotonicity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_column) \u001b[39mfor\u001b[39;00m groups_without_monotonicity \u001b[39min\u001b[39;00m population_interactions]\n\u001b[0;32m    607\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFinished init population\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    608\u001b[0m logging\u001b[39m.\u001b[39minfo(msg)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:337\u001b[0m, in \u001b[0;36mGroupStructure.detector_monotonicity\u001b[1;34m(data, included_groups_without_monotonicity, class_column)\u001b[0m\n\u001b[0;32m    335\u001b[0m dec_tree \u001b[39m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, min_samples_split\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m    336\u001b[0m dec_tree \u001b[39m=\u001b[39m dec_tree\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mdata_train\u001b[39m.\u001b[39miloc[:, [feature]], y\u001b[39m=\u001b[39mdata_train\u001b[39m.\u001b[39mloc[:, class_column])  \u001b[39m# expects DataFrame for X\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m y_pred \u001b[39m=\u001b[39m dec_tree\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mdata_test\u001b[39m.\u001b[39;49miloc[:, [feature]])  \u001b[39m# expects DataFrame for X\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m data_test\u001b[39m.\u001b[39miloc[:, feature]\u001b[39m.\u001b[39mnunique() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39munique(y_pred)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# spearmanr only defined if no input is constant\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     rhos\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:531\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    529\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    530\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 531\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    532\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    534\u001b[0m \u001b[39m# Classification\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 100,\n",
    "    'lambda': 10,\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "min_epochs = 200\n",
    "patience = 100\n",
    "\n",
    "secs_per_fold = 2 * 60\n",
    "secs_total = 8 * 60 * 60\n",
    "\n",
    "pareto_fronts = list()\n",
    "for (_, oml_dataset, class_positive) in zipped_instance_3:\n",
    "    name = oml_dataset.name\n",
    "    msg = f'Dataset {name}'\n",
    "    print(msg)\n",
    "    logging.info(msg)\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        min_epochs=min_epochs,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    #eagga.load_population(0)\n",
    "    \n",
    "    pareto_front = eagga.run_eagga()\n",
    "    pareto_fronts.append(pareto_front)\n",
    "pareto_fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
