{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "import torch\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from classes import Dataset, GroupStructure, WeightClipper\n",
    "from functions import run_HPO_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_task_diabetes = tasks.get_task(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, categorical_indicator, attribute_names = oml_task_diabetes.get_dataset().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg   plas  pres  skin   insu  mass   pedi   age            class\n",
       "0     6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  tested_positive\n",
       "1     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  tested_negative\n",
       "2     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  tested_positive\n",
       "3     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  tested_negative\n",
       "4     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  tested_positive\n",
       "..    ...    ...   ...   ...    ...   ...    ...   ...              ...\n",
       "763  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0  tested_negative\n",
       "764   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0  tested_negative\n",
       "765   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0  tested_negative\n",
       "766   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0  tested_positive\n",
       "767   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0  tested_negative\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([64.0000, 23.3000]),\n",
       "  tensor([0.]),\n",
       "  tensor([32.0000,  0.0000,  0.6720])),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GroupStructure(\n",
    "    {0, 1, 2, 3, 4, 5, 6, 7},\n",
    "    {0, 1},\n",
    "    ((2, 5), 1),\n",
    "    ((4,), 0),\n",
    "    ((7, 3, 6), 1)\n",
    ")\n",
    "\n",
    "tmp = Dataset(\n",
    "    X=Xy.loc[:, Xy.columns != 'class'],\n",
    "    y=Xy.loc[:, 'class'],\n",
    "    class_pos='tested_positive',\n",
    "    group_structure=gs\n",
    ")\n",
    "len(tmp)\n",
    "tmp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False, False, True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running HPO: 3 total_layers, 3 nodes per hidden layer\n",
      "fold 1 / 5\n",
      "epoch 0 / 10, eval loss 2.664642019913747\n",
      "epoch 1 / 10, train loss 1.6802518390692198\n",
      "epoch 1 / 10, eval loss 0.9423372928912823\n",
      "epoch 2 / 10, train loss 0.7961538519996864\n",
      "epoch 2 / 10, eval loss 0.793572357067695\n",
      "epoch 3 / 10, train loss 0.7387798772408412\n",
      "epoch 3 / 10, eval loss 0.7325937564556415\n",
      "epoch 4 / 10, train loss 0.7161610080645635\n",
      "epoch 4 / 10, eval loss 0.6987243157166702\n",
      "epoch 5 / 10, train loss 0.7022897807451395\n",
      "epoch 5 / 10, eval loss 0.6738495757946601\n",
      "epoch 6 / 10, train loss 0.6918869654719646\n",
      "epoch 6 / 10, eval loss 0.6692131482637845\n",
      "epoch 7 / 10, train loss 0.6885035330286393\n",
      "epoch 7 / 10, eval loss 0.6666606389559232\n",
      "epoch 8 / 10, train loss 0.685228015940923\n",
      "epoch 8 / 10, eval loss 0.6643588474163642\n",
      "epoch 9 / 10, train loss 0.6823135001155046\n",
      "epoch 9 / 10, eval loss 0.6623265995429113\n",
      "epoch 10 / 10, train loss 0.6797248056301703\n",
      "epoch 10 / 10, eval loss 0.6605393061271081\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.3250, 0.4482],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0015, 0.2755]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.4926, 0.0000],\n",
      "        [0.4697, 0.0000, 0.0000],\n",
      "        [0.5209, 0.4396, 0.2496]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.9287],\n",
      "        [ 0.7052],\n",
      "        [ 0.2478]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0127, -0.5528, -0.2700],\n",
      "        [ 0.2703,  0.0103, -0.0279],\n",
      "        [ 0.4828, -0.3716,  0.1947]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.4352, 0.2742, 0.1107],\n",
      "        [0.0000, 0.0110, 0.0000],\n",
      "        [0.4400, 0.0000, 0.0358]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.3596],\n",
      "        [0.3571, 0.0000, 0.0000],\n",
      "        [0.1530, 0.0291, 0.0324]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 2 / 5\n",
      "epoch 0 / 10, eval loss 0.982453139928671\n",
      "epoch 1 / 10, train loss 0.8951513921985259\n",
      "epoch 1 / 10, eval loss 0.9451378629757807\n",
      "epoch 2 / 10, train loss 0.8062993918473904\n",
      "epoch 2 / 10, eval loss 0.7444080343613257\n",
      "epoch 3 / 10, train loss 0.7617712490833722\n",
      "epoch 3 / 10, eval loss 0.7274662921061883\n",
      "epoch 4 / 10, train loss 0.746614946768834\n",
      "epoch 4 / 10, eval loss 0.7170927501641787\n",
      "epoch 5 / 10, train loss 0.7348018552248294\n",
      "epoch 5 / 10, eval loss 0.7086716890335083\n",
      "epoch 6 / 10, train loss 0.7251793616093122\n",
      "epoch 6 / 10, eval loss 0.7016551540448115\n",
      "epoch 7 / 10, train loss 0.7172094073433143\n",
      "epoch 7 / 10, eval loss 0.6957012644180884\n",
      "epoch 8 / 10, train loss 0.7105033879096692\n",
      "epoch 8 / 10, eval loss 0.6905690454519712\n",
      "epoch 9 / 10, train loss 0.7047829633721938\n",
      "epoch 9 / 10, eval loss 0.6860865675486051\n",
      "epoch 10 / 10, train loss 0.6998543836749517\n",
      "epoch 10 / 10, eval loss 0.6821279869629786\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.1742, 0.1583],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2811, 0.4138]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.3258, 0.0658, 0.0000],\n",
      "        [0.4630, 0.0310, 0.2692],\n",
      "        [0.0731, 0.4598, 0.3556]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.5300],\n",
      "        [-0.6597],\n",
      "        [-0.1159]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.4124, -0.5408,  0.4069],\n",
      "        [ 0.3879,  0.1749,  0.4185],\n",
      "        [ 0.0371, -0.5676,  0.3530]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.4516],\n",
      "        [0.3515, 0.0338, 0.0000],\n",
      "        [0.0000, 0.3428, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0468, 0.3144, 0.0466],\n",
      "        [0.5977, 0.0358, 0.2658],\n",
      "        [0.0000, 0.1972, 0.0483]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 3 / 5\n",
      "epoch 0 / 10, eval loss 1.0754519655154302\n",
      "epoch 1 / 10, train loss 1.1382417059861696\n",
      "epoch 1 / 10, eval loss 1.245679137798456\n",
      "epoch 2 / 10, train loss 0.9723219378636434\n",
      "epoch 2 / 10, eval loss 0.7397365111571091\n",
      "epoch 3 / 10, train loss 0.8230638440984946\n",
      "epoch 3 / 10, eval loss 0.6895297651107495\n",
      "epoch 4 / 10, train loss 0.7645077917438287\n",
      "epoch 4 / 10, eval loss 0.6671887957132779\n",
      "epoch 5 / 10, train loss 0.7287556299796472\n",
      "epoch 5 / 10, eval loss 0.6560898193946252\n",
      "epoch 6 / 10, train loss 0.705824341911536\n",
      "epoch 6 / 10, eval loss 0.6505717291281774\n",
      "epoch 7 / 10, train loss 0.6902843971665089\n",
      "epoch 7 / 10, eval loss 0.6480787281806653\n",
      "epoch 8 / 10, train loss 0.6790716241185482\n",
      "epoch 8 / 10, eval loss 0.6470945867208334\n",
      "epoch 9 / 10, train loss 0.6704573253026376\n",
      "epoch 9 / 10, eval loss 0.6466470567079691\n",
      "epoch 10 / 10, train loss 0.6633640911716682\n",
      "epoch 10 / 10, eval loss 0.6461475101801065\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0225, 0.5851],\n",
      "        [0.0000, 0.4735],\n",
      "        [0.0526, 0.5295]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.3373, 0.1232, 0.0000],\n",
      "        [0.2147, 0.5519, 0.0000],\n",
      "        [0.5512, 0.1521, 0.2101]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[ 0.0284],\n",
      "        [-0.3658],\n",
      "        [-0.7221]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0864, -0.2451, -0.3370],\n",
      "        [ 0.2085,  0.3579,  0.3706],\n",
      "        [-0.4751, -0.2121,  0.3738]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0226, 0.5321, 0.2019],\n",
      "        [0.0460, 0.0433, 0.0000],\n",
      "        [0.2416, 0.3550, 0.2329]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0421, 0.1474, 0.0449],\n",
      "        [0.0423, 0.2870, 0.0171],\n",
      "        [0.3959, 0.0124, 0.0054]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 4 / 5\n",
      "epoch 0 / 10, eval loss 4.613149065237779\n",
      "epoch 1 / 10, train loss 3.1440798972661677\n",
      "epoch 1 / 10, eval loss 2.7472496734788785\n",
      "epoch 2 / 10, train loss 1.8527798308775976\n",
      "epoch 2 / 10, eval loss 1.3973166776391177\n",
      "epoch 3 / 10, train loss 1.004372276365757\n",
      "epoch 3 / 10, eval loss 0.7649789635951703\n",
      "epoch 4 / 10, train loss 0.7151926767367583\n",
      "epoch 4 / 10, eval loss 0.6969095262197348\n",
      "epoch 5 / 10, train loss 0.6944517516172849\n",
      "epoch 5 / 10, eval loss 0.6910722301556513\n",
      "epoch 6 / 10, train loss 0.6902949242637708\n",
      "epoch 6 / 10, eval loss 0.6876203257303971\n",
      "epoch 7 / 10, train loss 0.687613389812983\n",
      "epoch 7 / 10, eval loss 0.6849771256630237\n",
      "epoch 8 / 10, train loss 0.6856272719227351\n",
      "epoch 8 / 10, eval loss 0.6825133241139926\n",
      "epoch 9 / 10, train loss 0.6838740414151778\n",
      "epoch 9 / 10, eval loss 0.6801201013418344\n",
      "epoch 10 / 10, train loss 0.6822279783395621\n",
      "epoch 10 / 10, eval loss 0.6778086102925814\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.3343, 0.0000],\n",
      "        [0.0351, 0.0000],\n",
      "        [0.3341, 0.0797]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0122, 0.0983, 0.1646],\n",
      "        [0.0060, 0.2278, 0.0049],\n",
      "        [0.1393, 0.0005, 0.0031]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[ 0.7688],\n",
      "        [-0.0693],\n",
      "        [ 0.3480]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[-0.2059,  0.4829,  0.4340],\n",
      "        [-0.2352, -0.0792,  0.4779],\n",
      "        [ 0.3268,  0.3861,  0.4066]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[3.1982e-07, 6.1441e-07, 2.0651e-01],\n",
      "        [1.2285e-02, 2.5325e-01, 4.3879e-02],\n",
      "        [4.0836e-01, 2.4937e-01, 1.9543e-01]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.4332],\n",
      "        [0.5211, 0.0221, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 5 / 5\n",
      "epoch 0 / 10, eval loss 1.5261229184957652\n",
      "epoch 1 / 10, train loss 0.9060441215450947\n",
      "epoch 1 / 10, eval loss 0.7213527743632977\n",
      "epoch 2 / 10, train loss 0.6768265607265326\n",
      "epoch 2 / 10, eval loss 0.6856645483237046\n",
      "epoch 3 / 10, train loss 0.6633120505855634\n",
      "epoch 3 / 10, eval loss 0.676305550795335\n",
      "epoch 4 / 10, train loss 0.6582696311748945\n",
      "epoch 4 / 10, eval loss 0.6697961091995239\n",
      "epoch 5 / 10, train loss 0.6546936843257684\n",
      "epoch 5 / 10, eval loss 0.6647726549552038\n",
      "epoch 6 / 10, train loss 0.6520022171048018\n",
      "epoch 6 / 10, eval loss 0.6605514792295603\n",
      "epoch 7 / 10, train loss 0.6498971415253786\n",
      "epoch 7 / 10, eval loss 0.6572175117639395\n",
      "epoch 8 / 10, train loss 0.6481655807449267\n",
      "epoch 8 / 10, eval loss 0.6545200966871701\n",
      "epoch 9 / 10, train loss 0.6463848495712647\n",
      "epoch 9 / 10, eval loss 0.6518228054046631\n",
      "epoch 10 / 10, train loss 0.6450960447008793\n",
      "epoch 10 / 10, eval loss 0.650224887407743\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.1613, 0.0000],\n",
      "        [0.0000, 0.0000]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0188, 0.0042, 0.0027],\n",
      "        [0.3474, 0.0098, 0.2868],\n",
      "        [0.3998, 0.4818, 0.1534]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.9219],\n",
      "        [0.6049],\n",
      "        [0.5222]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0358, -0.3139, -0.1908],\n",
      "        [-0.1124,  0.2110,  0.0329],\n",
      "        [ 0.3864,  0.5322,  0.4840]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.5921, 0.0000, 0.0102],\n",
      "        [0.0375, 0.2585, 0.0372],\n",
      "        [0.2228, 0.4506, 0.3322]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.3465, 0.0193],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0404, 0.0971, 0.1554]], requires_grad=True) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# outer\n",
    "data_train_test, data_val = train_test_split(\n",
    "    Xy,\n",
    "    train_size=2/3,\n",
    "    shuffle=True,\n",
    "    stratify=Xy.loc[:, 'class']\n",
    ")\n",
    "\n",
    "# reset indices as StratifiedKFold assumes 0-(n-1) index\n",
    "data_train_test = data_train_test.reset_index(drop=True)\n",
    "data_val = data_val.reset_index(drop=True)\n",
    "\n",
    "# inner\n",
    "cv_inner = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=False  # TODO: set to True\n",
    ")\n",
    "\n",
    "'''\n",
    "in each inner fold, run EAGGA + find an optimal pareto front of configurations for this specific fold\n",
    "then in the outer fold (holdout), compare each fold-specific optimal pareto front + select optimum\n",
    "'''\n",
    "monotonicity_weight_clipper = WeightClipper(0, None)  # enforce monotonicity by clipping weights to [0, infty) after each epoch (in def train)\n",
    "run_HPO_CV(cv_inner, data_train_test, epochs=10, batch_size=8, weight_clipper=monotonicity_weight_clipper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
