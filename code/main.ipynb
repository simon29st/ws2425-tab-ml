{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\\n%pip install openml\\n%pip install numpy\\n%pip install pandas\\n# cf. https://pytorch.org/get-started/locally/\\n#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\\n%pip install -U scikit-learn\\n%pip install scipy\\n%pip install -U pymoo\\n%pip list'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\n",
    "%pip install openml\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# cf. https://pytorch.org/get-started/locally/\n",
    "#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\n",
    "%pip install -U scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -U pymoo\n",
    "%pip list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diabetes\n",
      "Starting init population\n",
      "Finished init population\n",
      "Loaded population, offspring, pareto front of generation 4 from file, discarded previous population, offspring, pareto front\n",
      "Start EAGGA at 2025-03-03T01:07:02.295873\n",
      "Generation 5, evaluate 2 individuals\n",
      "Running 5-fold CV for individual: 3 total layers, 13 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 6, 7], [[[5], 1]])\n",
      "Fold 1/5 | trained for 104 epochs / 3.002 seconds | stopped early: False | metrics: {'loss': 0.6195981800556183, 'auc': np.float64(0.7060530679933665), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [0.7167836129665375, 0.6649053394794464, 0.64032843708992, 0.6365352869033813, 0.6456151008605957, 0.6558038890361786, 0.647215873003006, 0.6384815573692322, 0.635985255241394, 0.635899543762207, 0.6376856863498688, 0.6393909752368927, 0.6394235193729401, 0.6374885141849518, 0.6360593438148499, 0.6375201046466827, 0.6389392614364624, 0.6350575983524323, 0.6361174583435059, 0.637578010559082, 0.636033296585083, 0.6365429162979126, 0.637643426656723, 0.6399194896221161, 0.6341328918933868, 0.633154034614563, 0.632477343082428, 0.6350391209125519, 0.6353301107883453, 0.6344102323055267, 0.6312330663204193, 0.6313190758228302, 0.6329097151756287, 0.6339119374752045, 0.6379567980766296, 0.6341936588287354, 0.6341434419155121, 0.630774587392807, 0.6296537518501282, 0.6293995976448059, 0.633321613073349, 0.6377325057983398, 0.6312790215015411, 0.6292379796504974, 0.6346708536148071, 0.6311617195606232, 0.6307481825351715, 0.6286176145076752, 0.6278254091739655, 0.6280633211135864, 0.6300323903560638, 0.6323093771934509, 0.6277999579906464, 0.6274528801441193, 0.6270583271980286, 0.6298590302467346, 0.6343750953674316, 0.6293608546257019, 0.6278012990951538, 0.630127340555191, 0.6271484196186066, 0.6261201798915863, 0.6259445250034332, 0.6276805102825165, 0.6276556849479675, 0.6259311437606812, 0.6252796947956085, 0.6257412731647491, 0.6251978874206543, 0.6251519322395325, 0.6298482716083527, 0.6302027106285095, 0.6283321380615234, 0.6267294585704803, 0.626849502325058, 0.6246789693832397, 0.6244003772735596, 0.6239966154098511, 0.6249023675918579, 0.6275733411312103, 0.6263138353824615, 0.6235722005367279, 0.6263640820980072, 0.625249445438385, 0.624098926782608, 0.6253354847431183, 0.6243421733379364, 0.6237100958824158, 0.6229403614997864, 0.6240365505218506, 0.624506950378418, 0.6243191063404083, 0.6235402524471283, 0.6234326362609863, 0.6247608959674835, 0.6245816051959991, 0.6224376261234283, 0.6221341490745544, 0.6280200779438019, 0.6336779892444611, 0.62199667096138, 0.6236505210399628, 0.6225675940513611, 0.6219406425952911, 0.6226595938205719, 0.6229290962219238, 0.622365266084671]}\n",
      "Fold 2/5 | trained for 111 epochs / 3.01 seconds | stopped early: False | metrics: {'loss': 0.6363174617290497, 'auc': np.float64(0.699419568822554), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [0.6404832303524017, 0.6569813787937164, 0.6412411034107208, 0.6405583322048187, 0.6484950482845306, 0.6608666777610779, 0.6376802325248718, 0.6380728483200073, 0.6405289769172668, 0.6571270227432251, 0.65477254986763, 0.6508390009403229, 0.6420458853244781, 0.6405401527881622, 0.6355111002922058, 0.6428232491016388, 0.6370908915996552, 0.6446229815483093, 0.6700097322463989, 0.6624593436717987, 0.6341432929039001, 0.6339662373065948, 0.6345875561237335, 0.6347503662109375, 0.6425566673278809, 0.6438640654087067, 0.6337476074695587, 0.6341277360916138, 0.633009135723114, 0.6333268582820892, 0.6321616470813751, 0.6319000124931335, 0.6348868608474731, 0.6470673680305481, 0.6513649225234985, 0.6317800879478455, 0.6307547092437744, 0.630760133266449, 0.636407196521759, 0.6386237144470215, 0.6335829794406891, 0.6303732097148895, 0.6345313787460327, 0.6517069041728973, 0.6346725523471832, 0.6300269663333893, 0.6383884251117706, 0.6316771507263184, 0.63168665766716, 0.6287648975849152, 0.6294517517089844, 0.6276419460773468, 0.6304908096790314, 0.6310158371925354, 0.6411366164684296, 0.6271242499351501, 0.6279914677143097, 0.6281801164150238, 0.6284224092960358, 0.6270647346973419, 0.6286616921424866, 0.6327223479747772, 0.6303896009922028, 0.6328500509262085, 0.6311622262001038, 0.6352807581424713, 0.6249068677425385, 0.6242551505565643, 0.6389808058738708, 0.6383497714996338, 0.6291167140007019, 0.6253092885017395, 0.6387293636798859, 0.6230535805225372, 0.6244050860404968, 0.6279172003269196, 0.6262514293193817, 0.6228772401809692, 0.6239611506462097, 0.6224493980407715, 0.6332156956195831, 0.6240147650241852, 0.621934324502945, 0.6220084726810455, 0.6281099617481232, 0.6287585198879242, 0.6285170018672943, 0.6327995955944061, 0.6274416446685791, 0.6209273934364319, 0.6281629800796509, 0.6210203170776367, 0.6209301948547363, 0.6300941109657288, 0.6255722939968109, 0.6200564205646515, 0.6284023225307465, 0.6388808190822601, 0.6237362027168274, 0.6303033232688904, 0.6214356422424316, 0.6245920360088348, 0.631418377161026, 0.6200712323188782, 0.620039165019989, 0.6213061809539795, 0.6194227337837219, 0.6187507808208466, 0.6212647259235382, 0.6231728494167328, 0.6181656420230865, 0.6215876042842865]}\n",
      "Fold 3/5 | trained for 107 epochs / 2.982 seconds | stopped early: True | metrics: {'loss': 0.6319907605648041, 'auc': np.float64(0.6575692963752666), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [0.6834273934364319, 0.6713171899318695, 0.6671461164951324, 0.6623449623584747, 0.6632133424282074, 0.6621504724025726, 0.6622528433799744, 0.6609397828578949, 0.6610819101333618, 0.6603474617004395, 0.6658183038234711, 0.6597957909107208, 0.6595807075500488, 0.6592344343662262, 0.658829927444458, 0.6586054861545563, 0.661763072013855, 0.6638856828212738, 0.6612160503864288, 0.6578345596790314, 0.6608970761299133, 0.6577231884002686, 0.66066575050354, 0.6612862944602966, 0.6563131511211395, 0.6566987335681915, 0.6556911170482635, 0.6561588943004608, 0.6552214622497559, 0.6560551822185516, 0.6549504697322845, 0.6554375290870667, 0.6567240655422211, 0.6550067067146301, 0.6535976827144623, 0.658536970615387, 0.6578417718410492, 0.6536999344825745, 0.6544432044029236, 0.6520590484142303, 0.6518868505954742, 0.6519850492477417, 0.6540052592754364, 0.651898980140686, 0.6588411927223206, 0.6523266732692719, 0.6594959497451782, 0.6608647108078003, 0.6506333947181702, 0.6541941165924072, 0.652975469827652, 0.6490887701511383, 0.6516914367675781, 0.6485882103443146, 0.6484761834144592, 0.6480848789215088, 0.6474935114383698, 0.6499933302402496, 0.6479285061359406, 0.6466110944747925, 0.649557501077652, 0.6510927081108093, 0.6462599337100983, 0.6453554034233093, 0.6450202465057373, 0.6549065709114075, 0.6484936475753784, 0.6452916860580444, 0.648334264755249, 0.6482638120651245, 0.6431601941585541, 0.6460810601711273, 0.6487121284008026, 0.6444889307022095, 0.6425348222255707, 0.6423538029193878, 0.6425324976444244, 0.6414682269096375, 0.641784280538559, 0.6410853862762451, 0.6404224634170532, 0.6423718333244324, 0.6402064263820648, 0.6402971744537354, 0.6394129395484924, 0.6437335014343262, 0.6388000547885895, 0.6384719610214233, 0.6417051255702972, 0.6379546821117401, 0.6433887481689453, 0.6430094838142395, 0.6374009847640991, 0.6376309096813202, 0.6408171951770782, 0.6444178223609924, 0.6362733244895935, 0.6424520909786224, 0.6356777548789978, 0.6367790400981903, 0.6357263624668121, 0.6343452036380768, 0.6405196487903595, 0.6343362927436829, 0.6351354420185089, 0.636694073677063, 0.6342365741729736, 0.6538529098033905]}\n",
      "Fold 4/5 | trained for 109 epochs / 3.012 seconds | stopped early: False | metrics: {'loss': 0.639483630657196, 'auc': np.float64(0.6712962962962963), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [2.050603747367859, 1.6274228692054749, 1.1915241479873657, 0.8278665840625763, 0.6486899256706238, 0.6978713274002075, 0.7083262503147125, 0.6609575152397156, 0.6461635231971741, 0.6456620991230011, 0.646191269159317, 0.6525115966796875, 0.6483927369117737, 0.6476050317287445, 0.6473582684993744, 0.6477484405040741, 0.6475092470645905, 0.6573476493358612, 0.6541221141815186, 0.6462038457393646, 0.6453043222427368, 0.6466827094554901, 0.6436823010444641, 0.6471510231494904, 0.6583844721317291, 0.6559935510158539, 0.6452519297599792, 0.642111212015152, 0.6447617411613464, 0.643163412809372, 0.6419700980186462, 0.6467819511890411, 0.645279049873352, 0.6417628526687622, 0.642108291387558, 0.6443696618080139, 0.6451303064823151, 0.6430471837520599, 0.6563510298728943, 0.6533101797103882, 0.6534403860569, 0.6469221711158752, 0.6429328322410583, 0.6395490169525146, 0.6392506062984467, 0.6489984393119812, 0.6598269939422607, 0.6485757529735565, 0.6390874087810516, 0.6384275555610657, 0.6375775039196014, 0.6379261612892151, 0.6432903110980988, 0.6460945904254913, 0.6372490227222443, 0.6378610730171204, 0.6402354538440704, 0.6457579433917999, 0.6416017413139343, 0.6419142782688141, 0.6380090415477753, 0.6415689587593079, 0.6355737447738647, 0.6358103454113007, 0.6348268389701843, 0.6362409293651581, 0.6505034267902374, 0.6396806240081787, 0.6340221464633942, 0.6343575119972229, 0.6411335468292236, 0.6390670239925385, 0.633525550365448, 0.635757327079773, 0.6420508921146393, 0.6420779526233673, 0.6346859037876129, 0.6353563666343689, 0.6339705586433411, 0.6347053945064545, 0.6492728292942047, 0.6312108039855957, 0.6313426196575165, 0.6434000432491302, 0.6480658948421478, 0.6336378157138824, 0.6325603723526001, 0.6308887898921967, 0.6315312087535858, 0.6369622647762299, 0.6407802700996399, 0.6322214901447296, 0.6299761831760406, 0.6303192377090454, 0.6355060935020447, 0.6319486200809479, 0.6286716759204865, 0.6307932138442993, 0.6336361169815063, 0.6280247271060944, 0.6277473568916321, 0.6280144453048706, 0.6421466171741486, 0.6399035155773163, 0.6274165511131287, 0.6286234557628632, 0.6311379671096802, 0.6267071068286896, 0.6261228322982788, 0.6349630057811737]}\n",
      "Fold 5/5 | trained for 110 epochs / 3.023 seconds | stopped early: False | metrics: {'loss': 0.6388035416603088, 'auc': np.float64(0.6824494949494949), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [2.1931204795837402, 1.4284208416938782, 0.7745252251625061, 0.7336900234222412, 0.734190434217453, 0.6804434061050415, 0.6987512409687042, 0.6951296031475067, 0.680925726890564, 0.6825013756752014, 0.6827688217163086, 0.6801097691059113, 0.6759970784187317, 0.6767430603504181, 0.6820257902145386, 0.6792437136173248, 0.6741423308849335, 0.6730937063694, 0.6864789426326752, 0.6780294179916382, 0.6720214784145355, 0.6892861723899841, 0.6979821622371674, 0.6707737147808075, 0.6743403375148773, 0.6732919812202454, 0.6867985129356384, 0.668392151594162, 0.6746460199356079, 0.6769284009933472, 0.6814471781253815, 0.6701521575450897, 0.6682729125022888, 0.6826827824115753, 0.6651851832866669, 0.6732566058635712, 0.6856102645397186, 0.6771681904792786, 0.6639707386493683, 0.6640040576457977, 0.6692887246608734, 0.6679279804229736, 0.6670095920562744, 0.6638149917125702, 0.6616913378238678, 0.6615263819694519, 0.6686305701732635, 0.6601116061210632, 0.6667324900627136, 0.665167510509491, 0.6706964075565338, 0.6603327989578247, 0.6729137003421783, 0.6580606698989868, 0.6757291853427887, 0.6577092111110687, 0.6582946181297302, 0.6546251773834229, 0.6637665629386902, 0.6623425483703613, 0.6537303030490875, 0.6532705724239349, 0.6588131487369537, 0.6598801612854004, 0.6507908403873444, 0.6508902013301849, 0.6546191871166229, 0.6765270233154297, 0.6540140509605408, 0.6480227112770081, 0.6559175848960876, 0.6479687392711639, 0.6464078426361084, 0.6659509241580963, 0.6599558889865875, 0.6469934284687042, 0.6505821943283081, 0.6559573709964752, 0.6477304100990295, 0.643179327249527, 0.643835574388504, 0.6419973373413086, 0.6415636837482452, 0.6758160293102264, 0.6404423415660858, 0.6404216885566711, 0.6470354199409485, 0.6524707674980164, 0.6416600942611694, 0.6380568146705627, 0.6517913341522217, 0.6396826207637787, 0.6364169120788574, 0.6379981338977814, 0.6366480886936188, 0.6371497213840485, 0.6404164731502533, 0.6336850523948669, 0.633502870798111, 0.6542284488677979, 0.6322761476039886, 0.639935165643692, 0.6332341730594635, 0.6338587999343872, 0.6305538415908813, 0.6299930214881897, 0.6308444142341614, 0.6288880109786987, 0.6293199956417084, 0.6278764307498932]}\n",
      "Running 5-fold CV for individual: 3 total layers, 13 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 6, 7], [[[5], 1]])\n",
      "Fold 1/5 | trained for 112 epochs / 3.012 seconds | stopped early: False | metrics: {'loss': 0.6218697726726532, 'auc': np.float64(0.6774461028192372), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [0.6813452541828156, 0.6789171695709229, 0.6785758435726166, 0.6782505810260773, 0.679106205701828, 0.675799548625946, 0.6750957071781158, 0.6745324730873108, 0.6746906638145447, 0.6733999252319336, 0.6743257343769073, 0.6758926808834076, 0.6759508550167084, 0.6788694262504578, 0.6774548590183258, 0.674203485250473, 0.6692348420619965, 0.6697103381156921, 0.6682465374469757, 0.6687575578689575, 0.6729976832866669, 0.6728573441505432, 0.6718412637710571, 0.6665937900543213, 0.6667428016662598, 0.6691699028015137, 0.6678747534751892, 0.666491687297821, 0.6659768521785736, 0.6650051176548004, 0.661383181810379, 0.6620725989341736, 0.6603038907051086, 0.6647821366786957, 0.6693543791770935, 0.6705383658409119, 0.6613480448722839, 0.6582195162773132, 0.6590718030929565, 0.6573691368103027, 0.6599420607089996, 0.6640788316726685, 0.6612154543399811, 0.6557940244674683, 0.6552730202674866, 0.6565560698509216, 0.6591685116291046, 0.6605983972549438, 0.6534573435783386, 0.6529886424541473, 0.6538435816764832, 0.654323160648346, 0.6527873277664185, 0.6519427001476288, 0.6515012681484222, 0.6500998735427856, 0.6491961181163788, 0.6518963575363159, 0.6510056555271149, 0.6481988430023193, 0.6471345126628876, 0.6494995057582855, 0.6486029326915741, 0.6477575600147247, 0.6441220343112946, 0.6434799134731293, 0.6426109075546265, 0.6421902179718018, 0.6443832814693451, 0.6411741375923157, 0.6407573223114014, 0.6425495445728302, 0.643199235200882, 0.6412999331951141, 0.6443039178848267, 0.6471531093120575, 0.6410942077636719, 0.6369660198688507, 0.6357437670230865, 0.6353707909584045, 0.6395545899868011, 0.637051522731781, 0.6336861848831177, 0.6328735053539276, 0.6316798329353333, 0.6310611963272095, 0.630628377199173, 0.6300809979438782, 0.631717175245285, 0.6295553743839264, 0.6270787417888641, 0.6267265677452087, 0.6258983910083771, 0.625012993812561, 0.6244107484817505, 0.6231835186481476, 0.6221932768821716, 0.622585654258728, 0.6335940361022949, 0.6209757030010223, 0.6200724244117737, 0.6197642385959625, 0.6191257834434509, 0.6182297468185425, 0.6177176237106323, 0.6176722049713135, 0.6172729432582855, 0.6163591146469116, 0.6185023784637451, 0.6224882900714874, 0.6135499775409698, 0.611909806728363]}\n",
      "Fold 2/5 | trained for 110 epochs / 3.008 seconds | stopped early: False | metrics: {'loss': 0.6557425558567047, 'auc': np.float64(0.2945688225538972), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [3.6142503023147583, 3.0977678298950195, 2.5278130769729614, 1.9510557651519775, 1.3993151783943176, 0.9476297497749329, 0.7197618782520294, 0.7449712753295898, 0.7450816035270691, 0.7147456705570221, 0.7211461365222931, 0.7366063296794891, 0.7184849083423615, 0.7148885726928711, 0.7253995835781097, 0.7144487500190735, 0.7140389680862427, 0.7302791178226471, 0.7207498550415039, 0.7084843814373016, 0.708423912525177, 0.7077041864395142, 0.7088291645050049, 0.7099062204360962, 0.7097622752189636, 0.708459198474884, 0.7071328163146973, 0.7103011012077332, 0.7045480310916901, 0.704253762960434, 0.7037808299064636, 0.7041922807693481, 0.7055099904537201, 0.7079443335533142, 0.708794891834259, 0.7026416659355164, 0.7017498910427094, 0.7077374756336212, 0.7008776962757111, 0.7051471173763275, 0.7000202834606171, 0.6989508271217346, 0.6995059549808502, 0.6989448070526123, 0.7041763961315155, 0.709337592124939, 0.7023938596248627, 0.6973307132720947, 0.6960761249065399, 0.6952013075351715, 0.7004448175430298, 0.6974672377109528, 0.6939235329627991, 0.6970531642436981, 0.6939672529697418, 0.6934413015842438, 0.6917878985404968, 0.6920934319496155, 0.6951489150524139, 0.6914129853248596, 0.6902575492858887, 0.6896357834339142, 0.6918288767337799, 0.6939618289470673, 0.6950705051422119, 0.6940814256668091, 0.6890529990196228, 0.6894237995147705, 0.691583663225174, 0.694214791059494, 0.6888148784637451, 0.6839694678783417, 0.6842755377292633, 0.6830714643001556, 0.6824046671390533, 0.6817355453968048, 0.6829593479633331, 0.6874116361141205, 0.6882178783416748, 0.6795217394828796, 0.6789801120758057, 0.6814230382442474, 0.6955810487270355, 0.6812074780464172, 0.6776982247829437, 0.6760375797748566, 0.6845895648002625, 0.6809381246566772, 0.6744774878025055, 0.6740009784698486, 0.6742238700389862, 0.6754359304904938, 0.6754061579704285, 0.6739702224731445, 0.6730933785438538, 0.6712715923786163, 0.6694937944412231, 0.677213579416275, 0.6681847274303436, 0.6679387986660004, 0.6679666042327881, 0.6719209551811218, 0.6658884882926941, 0.6658216714859009, 0.6664918959140778, 0.6679700016975403, 0.663733035326004, 0.6628791987895966, 0.6625332832336426, 0.6622605323791504]}\n",
      "Fold 3/5 | trained for 111 epochs / 3.013 seconds | stopped early: False | metrics: {'loss': 0.645935446023941, 'auc': np.float64(0.680810234541578), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [3.2634100914001465, 2.4681508541107178, 1.6211955547332764, 0.9345555305480957, 0.6790298819541931, 0.7316704392433167, 0.7751172780990601, 0.7226168513298035, 0.6779943704605103, 0.6818330585956573, 0.6782823801040649, 0.679111897945404, 0.6988291442394257, 0.6915194690227509, 0.6775866746902466, 0.6771456301212311, 0.6766223311424255, 0.6780945360660553, 0.6795376241207123, 0.679410308599472, 0.6763483583927155, 0.6775324046611786, 0.6773186326026917, 0.6767996549606323, 0.675856202840805, 0.6772714257240295, 0.6812748312950134, 0.6756177544593811, 0.6762102246284485, 0.6858481466770172, 0.6783966422080994, 0.6770764291286469, 0.6757140457630157, 0.6751371920108795, 0.674818754196167, 0.6756395101547241, 0.6750195622444153, 0.6757136583328247, 0.683510810136795, 0.6843653619289398, 0.676594078540802, 0.676294207572937, 0.6740367710590363, 0.6738012135028839, 0.6747001111507416, 0.6820954382419586, 0.6797848641872406, 0.6746999323368073, 0.6779573559761047, 0.676198422908783, 0.6739255487918854, 0.67697474360466, 0.6739621460437775, 0.6759395003318787, 0.6738502681255341, 0.672469824552536, 0.6722570359706879, 0.6730972528457642, 0.6877424418926239, 0.6813457310199738, 0.6714694201946259, 0.6716115176677704, 0.6711519658565521, 0.6724032163619995, 0.6874634921550751, 0.6783473193645477, 0.6704886853694916, 0.6819818317890167, 0.6715918183326721, 0.69977006316185, 0.6723280251026154, 0.6697522401809692, 0.6759488582611084, 0.6853510737419128, 0.670621395111084, 0.6693159937858582, 0.6798485815525055, 0.6787960827350616, 0.6696929931640625, 0.6693532168865204, 0.6684046387672424, 0.6726391017436981, 0.670063704252243, 0.6679441630840302, 0.6759119629859924, 0.6765577495098114, 0.6674816608428955, 0.6688835620880127, 0.6802563369274139, 0.666999489068985, 0.6676209568977356, 0.6669975817203522, 0.6668667197227478, 0.6789075136184692, 0.6777470707893372, 0.666670948266983, 0.6658314764499664, 0.6753781139850616, 0.6750980019569397, 0.6672106683254242, 0.6650881171226501, 0.6743887364864349, 0.672254890203476, 0.6646070182323456, 0.6675693988800049, 0.669609397649765, 0.6715798377990723, 0.6648766994476318, 0.668350875377655, 0.6669664680957794, 0.6638011038303375]}\n",
      "Fold 4/5 | trained for 113 epochs / 3.004 seconds | stopped early: False | metrics: {'loss': 0.6533714234828949, 'auc': np.float64(0.38741582491582494), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [9.568179607391357, 8.391606330871582, 7.113542556762695, 5.862695693969727, 4.6448893547058105, 3.44012987613678, 2.2822859287261963, 1.2454822063446045, 0.6900620460510254, 0.6731451749801636, 0.7060570120811462, 0.674131840467453, 0.6482301354408264, 0.6529917120933533, 0.6578581929206848, 0.6548792719841003, 0.6529935598373413, 0.6538096070289612, 0.6578568518161774, 0.6525322198867798, 0.6474016904830933, 0.6471966207027435, 0.64976966381073, 0.6572805345058441, 0.6587977111339569, 0.6498062312602997, 0.6469098627567291, 0.6497032344341278, 0.6494922339916229, 0.6567296087741852, 0.6558031439781189, 0.6516993641853333, 0.6471780836582184, 0.649041473865509, 0.6530128121376038, 0.6656821072101593, 0.6508764028549194, 0.6453897953033447, 0.6445750594139099, 0.6484003663063049, 0.648247241973877, 0.6466364562511444, 0.6438615024089813, 0.6436211168766022, 0.643250048160553, 0.6433974504470825, 0.6428296864032745, 0.6437181830406189, 0.6490737795829773, 0.6533012390136719, 0.6477212309837341, 0.6485277712345123, 0.6445221602916718, 0.6438182294368744, 0.6511178910732269, 0.6520160734653473, 0.6408559381961823, 0.6408502161502838, 0.6404868364334106, 0.6418823301792145, 0.6468566358089447, 0.6424985826015472, 0.6398106515407562, 0.640505462884903, 0.6441880464553833, 0.6419788002967834, 0.6453763544559479, 0.6391868889331818, 0.6419868171215057, 0.640323281288147, 0.6506004631519318, 0.6398085355758667, 0.6427124738693237, 0.6376028060913086, 0.6464521288871765, 0.6465333700180054, 0.6410761177539825, 0.6373780965805054, 0.6367812752723694, 0.636748343706131, 0.6360859274864197, 0.6360124945640564, 0.6365683078765869, 0.6437135636806488, 0.6487517654895782, 0.6411480009555817, 0.6353456676006317, 0.6458360254764557, 0.6363372802734375, 0.6340835988521576, 0.6519163250923157, 0.6420897543430328, 0.6338851153850555, 0.6346168220043182, 0.6332813501358032, 0.6393793821334839, 0.6478639841079712, 0.6330997347831726, 0.6320795118808746, 0.6328464448451996, 0.6348214149475098, 0.6532532274723053, 0.6344100832939148, 0.6317026913166046, 0.6423406898975372, 0.639286994934082, 0.6313464045524597, 0.6312375664710999, 0.6424894630908966, 0.633527398109436, 0.6303408443927765, 0.630669891834259, 0.6300300061702728]}\n",
      "Fold 5/5 | trained for 96 epochs / 2.812 seconds | stopped early: True | metrics: {'loss': 0.6498799026012421, 'auc': np.float64(0.7411616161616162), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [1.4229723811149597, 1.0292412638664246, 0.717776358127594, 0.6558727920055389, 0.703927755355835, 0.6972167491912842, 0.6508252322673798, 0.6451641023159027, 0.6451234519481659, 0.6538110673427582, 0.6532995402812958, 0.6484383046627045, 0.6463004052639008, 0.666937530040741, 0.6822366416454315, 0.6499433219432831, 0.6464658081531525, 0.6434902846813202, 0.6571012139320374, 0.6527434885501862, 0.6449443995952606, 0.6537969708442688, 0.6444158256053925, 0.6430672705173492, 0.64804407954216, 0.6772075593471527, 0.6896062195301056, 0.641764223575592, 0.6424469947814941, 0.6539381444454193, 0.6799200177192688, 0.643845409154892, 0.6417571306228638, 0.6425699591636658, 0.6467365622520447, 0.6440051794052124, 0.6408058106899261, 0.6410134434700012, 0.6545875072479248, 0.6465242207050323, 0.6407661736011505, 0.6437215507030487, 0.6594046950340271, 0.6524136960506439, 0.6390877962112427, 0.6405916512012482, 0.6439710557460785, 0.6381697356700897, 0.6383113265037537, 0.6443507969379425, 0.6722165942192078, 0.6390988230705261, 0.644923985004425, 0.6504952311515808, 0.6531187295913696, 0.6436802446842194, 0.6474450826644897, 0.640716940164566, 0.6361490488052368, 0.6483466923236847, 0.6591154038906097, 0.6357101500034332, 0.6358366012573242, 0.6393449008464813, 0.6422065794467926, 0.66363126039505, 0.635155588388443, 0.6349815726280212, 0.6350012123584747, 0.6381756067276001, 0.634256511926651, 0.63411745429039, 0.6507201790809631, 0.638409286737442, 0.6343913972377777, 0.6341599524021149, 0.6369382441043854, 0.6374976933002472, 0.6333005726337433, 0.6344870626926422, 0.6431156992912292, 0.6329046487808228, 0.6325982809066772, 0.6398953497409821, 0.6413255035877228, 0.632565438747406, 0.6342108249664307, 0.6435976028442383, 0.634805291891098, 0.6320168673992157, 0.6400822699069977, 0.6432787179946899, 0.6386576294898987, 0.6513639092445374, 0.6312127411365509, 0.6309588253498077, 0.6343898177146912, 0.6366510391235352, 0.6403281092643738, 0.6319216191768646, 0.6315603852272034, 0.6311978995800018, 0.6461742520332336, 0.6606667041778564]}\n",
      "\n",
      "Compiled modules for significant speedup can not be used!\n",
      "https://pymoo.org/installation.html#installation\n",
      "\n",
      "To disable this warning:\n",
      "from pymoo.config import Config\n",
      "Config.warnings['not_compiled'] = False\n",
      "\n",
      "Dominated Hypervolume: 0.349609375 for Pareto front [[0.687416   0.125      0.         0.        ]\n",
      " [0.65039062 0.         0.         0.        ]]\n",
      "Autosaving generation 5 to export/diabetes\n",
      "Saved population, offspring, pareto front of generation 5 to file\n",
      "Generation 6, evaluate 2 individuals\n",
      "Running 5-fold CV for individual: 3 total layers, 13 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 6, 7], [[[5], 1]])\n",
      "Fold 1/5 | trained for 93 epochs / 3.018 seconds | stopped early: False | metrics: {'loss': 0.635753870010376, 'auc': np.float64(0.685530679933665), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [1.2707403898239136, 1.0104589760303497, 0.7296727895736694, 0.6427824795246124, 0.6497405469417572, 0.6525669395923615, 0.6493307054042816, 0.6424062252044678, 0.641571968793869, 0.642114132642746, 0.6403610408306122, 0.6401227116584778, 0.640477865934372, 0.6407669186592102, 0.6389614939689636, 0.6385506689548492, 0.6387817561626434, 0.6405288875102997, 0.6378516852855682, 0.6383162140846252, 0.6371984779834747, 0.6366669833660126, 0.6363588869571686, 0.6357870399951935, 0.6354144215583801, 0.6351089477539062, 0.6346103549003601, 0.6351474821567535, 0.6355345547199249, 0.6340055763721466, 0.6355335116386414, 0.6344473361968994, 0.6326148211956024, 0.6325976848602295, 0.6332298219203949, 0.6344879865646362, 0.6351160407066345, 0.6313786506652832, 0.6303461492061615, 0.6296387314796448, 0.6321823596954346, 0.6288810968399048, 0.6285258829593658, 0.6281591355800629, 0.629053384065628, 0.631087452173233, 0.6330893039703369, 0.6269258260726929, 0.6272722482681274, 0.6275627911090851, 0.6295923590660095, 0.6264806985855103, 0.6282152235507965, 0.6270486116409302, 0.6275978684425354, 0.6348347961902618, 0.62439826130867, 0.623923659324646, 0.6241357922554016, 0.6222788095474243, 0.6248454451560974, 0.622675746679306, 0.6211902499198914, 0.6202815771102905, 0.6202390193939209, 0.6255393028259277, 0.6196123659610748, 0.6194531321525574, 0.6183462142944336, 0.6213839054107666, 0.6188852488994598, 0.6230829358100891, 0.6216631233692169, 0.6194944083690643, 0.6222780048847198, 0.6246504783630371, 0.6197701394557953, 0.6162564754486084, 0.6184530854225159, 0.6187914907932281, 0.6198370456695557, 0.6198325753211975, 0.6141887903213501, 0.6131957173347473, 0.6296685338020325, 0.6126865446567535, 0.6115970611572266, 0.6142856180667877, 0.6112194061279297, 0.6100726425647736, 0.6113218069076538, 0.6102420389652252, 0.6096973121166229]}\n",
      "Fold 2/5 | trained for 93 epochs / 3.015 seconds | stopped early: False | metrics: {'loss': 0.6422976553440094, 'auc': np.float64(0.6540215588723051), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [4.066171407699585, 3.390627384185791, 2.6553866863250732, 1.9180227518081665, 1.250599980354309, 0.8028778731822968, 0.6525544822216034, 0.6675359904766083, 0.6869106590747833, 0.6722993850708008, 0.6507600545883179, 0.6481639444828033, 0.6560971438884735, 0.6532406508922577, 0.6507994830608368, 0.6473704874515533, 0.6475520730018616, 0.6497098207473755, 0.6466642618179321, 0.6460061371326447, 0.6460370421409607, 0.6470938622951508, 0.6544941663742065, 0.6505173146724701, 0.6457232534885406, 0.6452012360095978, 0.6450090706348419, 0.6450575292110443, 0.6510143280029297, 0.6573034822940826, 0.6515989005565643, 0.643812745809555, 0.6442922949790955, 0.643574595451355, 0.6470704674720764, 0.649864137172699, 0.6514566540718079, 0.6444096267223358, 0.6430613100528717, 0.6421628594398499, 0.6422940492630005, 0.6510841846466064, 0.6496886312961578, 0.6414901912212372, 0.6416525840759277, 0.6409852504730225, 0.6428326964378357, 0.644718587398529, 0.6410470902919769, 0.6402436196804047, 0.6396035850048065, 0.6392342746257782, 0.6392065584659576, 0.639222651720047, 0.6391491591930389, 0.6435472667217255, 0.640683114528656, 0.6377532780170441, 0.6375157833099365, 0.6380401849746704, 0.6397735178470612, 0.6370310187339783, 0.6372432112693787, 0.6388944983482361, 0.6363958418369293, 0.667121946811676, 0.661782443523407, 0.6380697786808014, 0.6351048052310944, 0.6369534432888031, 0.6360315680503845, 0.6338457465171814, 0.6354436278343201, 0.6347713768482208, 0.6342274844646454, 0.6335005760192871, 0.6364654004573822, 0.6334396600723267, 0.6341819763183594, 0.6315696239471436, 0.6315698325634003, 0.631479799747467, 0.6337802708148956, 0.6316292881965637, 0.6327076256275177, 0.6360286474227905, 0.6302756369113922, 0.6293473541736603, 0.6294358670711517, 0.6376660764217377, 0.6362742185592651, 0.6292438209056854, 0.6272352039813995, 0.6272715628147125, 0.6277126371860504]}\n",
      "Fold 3/5 | trained for 106 epochs / 3.017 seconds | stopped early: False | metrics: {'loss': 0.6453120410442352, 'auc': np.float64(0.666950959488273), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [1.338563859462738, 0.9090661108493805, 0.6885780096054077, 0.6664215624332428, 0.6723338067531586, 0.6640075445175171, 0.6703067719936371, 0.6735754609107971, 0.6678707301616669, 0.6644503772258759, 0.6638776659965515, 0.6637077629566193, 0.6623047292232513, 0.6636495292186737, 0.6637095212936401, 0.6660252511501312, 0.6698514819145203, 0.6613044738769531, 0.6609345972537994, 0.6609679162502289, 0.6603639125823975, 0.6602459847927094, 0.665359377861023, 0.6737156510353088, 0.664547860622406, 0.6591136753559113, 0.660060465335846, 0.6586103439331055, 0.6672642827033997, 0.6710378229618073, 0.6580038070678711, 0.6576728820800781, 0.6573011875152588, 0.6597626209259033, 0.6639165878295898, 0.6726419627666473, 0.661311149597168, 0.6559268534183502, 0.6570094525814056, 0.6581174433231354, 0.6627648174762726, 0.6608352661132812, 0.6691152453422546, 0.6624945104122162, 0.6539803147315979, 0.6540710031986237, 0.6559677720069885, 0.655478835105896, 0.6527543067932129, 0.653128981590271, 0.6522763669490814, 0.6517287790775299, 0.6532542407512665, 0.6518276035785675, 0.651030421257019, 0.653866708278656, 0.6502762138843536, 0.6498594880104065, 0.652195930480957, 0.6523529291152954, 0.6490239202976227, 0.6510003805160522, 0.6515029668807983, 0.6556255519390106, 0.6477702856063843, 0.6473067700862885, 0.6509329080581665, 0.6491020917892456, 0.6552820801734924, 0.6497927308082581, 0.6478642225265503, 0.6494262516498566, 0.645078718662262, 0.6508576273918152, 0.6591877639293671, 0.648181140422821, 0.6433173418045044, 0.6428395211696625, 0.6468613147735596, 0.6588012278079987, 0.6427371203899384, 0.6416607797145844, 0.6631276607513428, 0.6616752743721008, 0.6410446763038635, 0.6414934992790222, 0.6395652294158936, 0.6393995881080627, 0.6389359533786774, 0.6390241980552673, 0.649500161409378, 0.6470690369606018, 0.637954443693161, 0.6438240706920624, 0.6496462821960449, 0.6432507932186127, 0.6361358165740967, 0.639681488275528, 0.6545847058296204, 0.6468098759651184, 0.6354060173034668, 0.6344771087169647, 0.6344615519046783, 0.634000837802887, 0.6339029967784882, 0.6332229375839233]}\n",
      "Fold 4/5 | trained for 93 epochs / 3.0 seconds | stopped early: False | metrics: {'loss': 0.6530285179615021, 'auc': np.float64(0.7205387205387205), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [2.394987940788269, 1.8191725611686707, 1.2002991437911987, 0.7377743721008301, 0.6954453587532043, 0.7211619317531586, 0.6691385507583618, 0.6801076829433441, 0.6732785105705261, 0.6686412692070007, 0.6703430712223053, 0.6702017784118652, 0.6677854061126709, 0.6709484755992889, 0.6768407225608826, 0.6731051504611969, 0.6695811450481415, 0.6671066284179688, 0.6745697259902954, 0.6802407801151276, 0.6701050698757172, 0.6662943065166473, 0.6660061478614807, 0.6720812916755676, 0.6785978078842163, 0.6668660938739777, 0.6653646230697632, 0.6675898432731628, 0.6776825487613678, 0.664717435836792, 0.6645247638225555, 0.6742062270641327, 0.6783514618873596, 0.6703815162181854, 0.6640705764293671, 0.6635995805263519, 0.6634471714496613, 0.6636643707752228, 0.6665599942207336, 0.6629573106765747, 0.6633541584014893, 0.6631152331829071, 0.6806915402412415, 0.6629224121570587, 0.6637488901615143, 0.6637479662895203, 0.6868098378181458, 0.6744842231273651, 0.6616259813308716, 0.6628624498844147, 0.663375973701477, 0.6652836501598358, 0.660468578338623, 0.6604441702365875, 0.6701192855834961, 0.6732155382633209, 0.6613878905773163, 0.6602091789245605, 0.6595944464206696, 0.6685722470283508, 0.6714777648448944, 0.6614420413970947, 0.6727829575538635, 0.6776128709316254, 0.6639826595783234, 0.6583336889743805, 0.659451812505722, 0.6585146486759186, 0.660129725933075, 0.6586677134037018, 0.6600999534130096, 0.6628747880458832, 0.6565654873847961, 0.656483381986618, 0.6671559512615204, 0.6609984040260315, 0.6560303866863251, 0.656389057636261, 0.662048876285553, 0.6686170995235443, 0.6561976373195648, 0.6574633717536926, 0.6552177667617798, 0.6550507545471191, 0.6574192941188812, 0.6535896062850952, 0.6582489013671875, 0.6736064553260803, 0.669925183057785, 0.6583790183067322, 0.6524521112442017, 0.6522342264652252, 0.6520816683769226]}\n",
      "Fold 5/5 | trained for 107 epochs / 3.023 seconds | stopped early: False | metrics: {'loss': 0.6448688507080078, 'auc': np.float64(0.2977693602693603), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [5.672924518585205, 4.702723503112793, 3.6784114837646484, 2.689117431640625, 1.7772018909454346, 1.0577009916305542, 0.7008716464042664, 0.6626912951469421, 0.6876714527606964, 0.6836279928684235, 0.6618591547012329, 0.6588764190673828, 0.662911593914032, 0.6689602434635162, 0.6686350703239441, 0.6626891195774078, 0.6572170853614807, 0.6592006981372833, 0.657116711139679, 0.6581690013408661, 0.6596788763999939, 0.6620871126651764, 0.6604485511779785, 0.6590535640716553, 0.6585898399353027, 0.6618963181972504, 0.6575874984264374, 0.6568028628826141, 0.6572441756725311, 0.6600506901741028, 0.6598119139671326, 0.6563774645328522, 0.6563661694526672, 0.6571288704872131, 0.661661833524704, 0.6594445705413818, 0.6587079763412476, 0.6579733788967133, 0.6562537550926208, 0.6562004089355469, 0.6566109955310822, 0.656279593706131, 0.6563814878463745, 0.6578081846237183, 0.6589660942554474, 0.6562367081642151, 0.6555142998695374, 0.6553223729133606, 0.6575683057308197, 0.6573210060596466, 0.655958890914917, 0.6562194228172302, 0.6574003398418427, 0.6590847373008728, 0.6635294556617737, 0.6576752066612244, 0.6554203629493713, 0.6544705331325531, 0.6548247933387756, 0.6554341018199921, 0.6637206375598907, 0.6563125550746918, 0.6582991480827332, 0.6559019982814789, 0.6539343595504761, 0.6560639441013336, 0.6605905294418335, 0.6549881100654602, 0.6542943120002747, 0.6536001563072205, 0.6539524793624878, 0.6540984213352203, 0.6545930802822113, 0.6538553833961487, 0.6533435881137848, 0.6665753424167633, 0.6581238508224487, 0.6528973281383514, 0.6531208455562592, 0.6627392470836639, 0.6610881388187408, 0.6524953842163086, 0.6528674066066742, 0.6540220975875854, 0.6587399244308472, 0.6611070036888123, 0.6520674824714661, 0.6553276479244232, 0.6520335674285889, 0.6528231203556061, 0.6555515229701996, 0.6531307101249695, 0.6515050828456879, 0.6517249047756195, 0.6516831815242767, 0.6535426676273346, 0.6513023674488068, 0.6511953473091125, 0.651529461145401, 0.6511612236499786, 0.651001363992691, 0.6536285281181335, 0.6507775485515594, 0.6508080065250397, 0.6513605117797852, 0.6507558226585388, 0.6504104435443878, 0.6504279971122742, 0.6563344895839691, 0.6532419621944427]}\n",
      "Running 5-fold CV for individual: 3 total layers, 13 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 6, 7], [[[5], 1]])\n",
      "Fold 1/5 | trained for 109 epochs / 3.012 seconds | stopped early: False | metrics: {'loss': 0.633861780166626, 'auc': np.float64(0.6048922056384743), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [1.6583924889564514, 0.9325747191905975, 0.6699053943157196, 0.7143246531486511, 0.7041744291782379, 0.6692830920219421, 0.687259316444397, 0.6816716492176056, 0.6682064831256866, 0.6752572059631348, 0.67378169298172, 0.6671789288520813, 0.6687343418598175, 0.6714102625846863, 0.6658418476581573, 0.666597306728363, 0.6651409566402435, 0.6678746938705444, 0.6647155284881592, 0.6638641357421875, 0.6638686060905457, 0.6632088422775269, 0.6631970107555389, 0.6612028181552887, 0.670782059431076, 0.6630271077156067, 0.6778983771800995, 0.6648770570755005, 0.6607711315155029, 0.6579812467098236, 0.6620907783508301, 0.6570907533168793, 0.6648658514022827, 0.6558773517608643, 0.6606635749340057, 0.6571119725704193, 0.6541809737682343, 0.6542799472808838, 0.6533022522926331, 0.6530201733112335, 0.652184933423996, 0.660209059715271, 0.6560461223125458, 0.6599140465259552, 0.65085768699646, 0.6678144931793213, 0.6485697627067566, 0.658424973487854, 0.6485821306705475, 0.6526167392730713, 0.6594012379646301, 0.6465971767902374, 0.6462593078613281, 0.6458714306354523, 0.6451339423656464, 0.6445703506469727, 0.6443881988525391, 0.6518576443195343, 0.6437116861343384, 0.6488883793354034, 0.6463381052017212, 0.643027663230896, 0.6419394910335541, 0.6412658989429474, 0.6426678895950317, 0.6404005885124207, 0.6429538130760193, 0.6441571712493896, 0.6395511031150818, 0.640038788318634, 0.6399154663085938, 0.637016236782074, 0.6451787650585175, 0.636521965265274, 0.6367101073265076, 0.6356822848320007, 0.6348717212677002, 0.6357009708881378, 0.6348071396350861, 0.6328086853027344, 0.636885404586792, 0.6337300539016724, 0.6403903663158417, 0.6311953067779541, 0.6324373781681061, 0.630107969045639, 0.6297005414962769, 0.6334211528301239, 0.6341744959354401, 0.6283077001571655, 0.6447867453098297, 0.6323710978031158, 0.627291351556778, 0.6286060810089111, 0.6293571293354034, 0.6264259815216064, 0.6265762448310852, 0.6262046694755554, 0.6253437101840973, 0.6259733438491821, 0.6259652078151703, 0.6291972100734711, 0.6238545477390289, 0.6244012117385864, 0.6252965331077576, 0.6245492398738861, 0.6278691291809082, 0.6286123096942902, 0.6222509145736694, 0.6227799355983734, 0.6238915324211121]}\n",
      "Fold 2/5 | trained for 108 epochs / 2.989 seconds | stopped early: True | metrics: {'loss': 0.6337988376617432, 'auc': np.float64(0.6925787728026533), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [1.42588210105896, 1.1108215749263763, 0.8257497549057007, 0.6624431312084198, 0.6647501289844513, 0.717413455247879, 0.6783176362514496, 0.6470814943313599, 0.6460176706314087, 0.645172655582428, 0.6474921107292175, 0.6475048065185547, 0.6533183157444, 0.6605329811573029, 0.6465066373348236, 0.6442381739616394, 0.6474247872829437, 0.6477266848087311, 0.6470653414726257, 0.644374668598175, 0.6483299434185028, 0.6461785137653351, 0.6438200771808624, 0.642961323261261, 0.6427983939647675, 0.6440323293209076, 0.6565781533718109, 0.6516956090927124, 0.6422938406467438, 0.6420898139476776, 0.6527621746063232, 0.6547407507896423, 0.6444486677646637, 0.6467726826667786, 0.6508574783802032, 0.6480432152748108, 0.6467690169811249, 0.6417321562767029, 0.6461580395698547, 0.6550315618515015, 0.6432323753833771, 0.6465760767459869, 0.643742024898529, 0.6453964412212372, 0.6495368480682373, 0.6417255103588104, 0.6386136114597321, 0.6381990611553192, 0.6460829079151154, 0.6565797924995422, 0.6533146500587463, 0.6385915279388428, 0.6377570927143097, 0.6437649428844452, 0.6541468501091003, 0.6409869492053986, 0.6372664272785187, 0.6362099349498749, 0.6466590464115143, 0.646377295255661, 0.6362716853618622, 0.635456919670105, 0.6434849500656128, 0.6399592459201813, 0.6406333148479462, 0.6349955797195435, 0.6349318027496338, 0.6364818513393402, 0.6371185481548309, 0.6362901031970978, 0.6434935629367828, 0.6436267197132111, 0.6335073709487915, 0.635190486907959, 0.6436788439750671, 0.6484252214431763, 0.6320189237594604, 0.631820946931839, 0.6324116885662079, 0.6314736306667328, 0.6481056213378906, 0.6496254801750183, 0.6309608519077301, 0.6392617523670197, 0.6313079595565796, 0.659502238035202, 0.634109377861023, 0.6302211880683899, 0.6327473521232605, 0.6316866874694824, 0.6292675137519836, 0.6365830898284912, 0.6334826350212097, 0.6394979655742645, 0.6292241811752319, 0.6289839148521423, 0.6359789073467255, 0.6464529633522034, 0.6277196705341339, 0.6274504363536835, 0.629677951335907, 0.6393612921237946, 0.6386041343212128, 0.6321074366569519, 0.6267901062965393, 0.6362244784832001, 0.630521833896637, 0.6258831322193146, 0.637716144323349, 0.6502805054187775]}\n",
      "Fold 3/5 | trained for 101 epochs / 2.747 seconds | stopped early: True | metrics: {'loss': 0.6333863437175751, 'auc': np.float64(0.7260127931769723), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0, 'losses_stop_early': [0.6841029226779938, 0.7184871733188629, 0.6827503740787506, 0.6797173321247101, 0.6861810982227325, 0.6866925954818726, 0.6792163848876953, 0.6777093708515167, 0.6778039932250977, 0.6849430203437805, 0.6771085858345032, 0.6801110804080963, 0.6752923727035522, 0.6745530664920807, 0.678207516670227, 0.6824371814727783, 0.6733957231044769, 0.674703061580658, 0.6765310168266296, 0.6720902323722839, 0.6709010601043701, 0.6835570633411407, 0.6724981367588043, 0.6699995994567871, 0.7023958265781403, 0.668354719877243, 0.674534797668457, 0.6844877302646637, 0.6726613342761993, 0.6745891273021698, 0.6691148579120636, 0.6681750118732452, 0.671942263841629, 0.6670782566070557, 0.6675268709659576, 0.6742686033248901, 0.6697754263877869, 0.668187826871872, 0.6746624708175659, 0.6640294790267944, 0.6650868356227875, 0.671962708234787, 0.6635281145572662, 0.6603778898715973, 0.6607553362846375, 0.6604838669300079, 0.6664522290229797, 0.667983204126358, 0.6585476398468018, 0.6579949259757996, 0.6629001796245575, 0.6577660441398621, 0.6585782468318939, 0.6584941744804382, 0.6689163148403168, 0.6568473279476166, 0.6610476970672607, 0.6573821306228638, 0.6542510688304901, 0.6548705995082855, 0.6524703204631805, 0.6528621912002563, 0.6522068083286285, 0.651634931564331, 0.6537923514842987, 0.6776468753814697, 0.6531593203544617, 0.6493254899978638, 0.6848948299884796, 0.6487126052379608, 0.6481594741344452, 0.6585184037685394, 0.6574728786945343, 0.6475532650947571, 0.6483052968978882, 0.6485020518302917, 0.6511462330818176, 0.6500826776027679, 0.6495057642459869, 0.6450238227844238, 0.6467059850692749, 0.6443639695644379, 0.6509667932987213, 0.6435184180736542, 0.6449615955352783, 0.6426564157009125, 0.6421561241149902, 0.6434130966663361, 0.6688048243522644, 0.6433311998844147, 0.6451013088226318, 0.6570712327957153, 0.6408574283123016, 0.639839380979538, 0.6391266882419586, 0.6540881395339966, 0.6411752700805664, 0.6381274461746216, 0.6651805639266968, 0.639122486114502, 0.6373408436775208, 0.6695101261138916]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m\n\u001b[0;32m     23\u001b[0m eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     24\u001b[0m     oml_dataset\u001b[39m=\u001b[39moml_dataset,\n\u001b[0;32m     25\u001b[0m     class_positive\u001b[39m=\u001b[39mclass_positive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     file_path\u001b[39m=\u001b[39mfile_path\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m eagga\u001b[39m.\u001b[39mload_population(\u001b[39m3\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m pareto_front \u001b[39m=\u001b[39m eagga\u001b[39m.\u001b[39;49mrun_eagga()\n\u001b[0;32m     36\u001b[0m pareto_fronts\u001b[39m.\u001b[39mappend(pareto_front)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:588\u001b[0m, in \u001b[0;36mEAGGA.run_eagga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGeneration \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, evaluate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring)\u001b[39m}\u001b[39;00m\u001b[39m individuals\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring:\n\u001b[1;32m--> 588\u001b[0m     individual[\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_cv(individual)\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation\u001b[39m.\u001b[39mappend(individual)\n\u001b[0;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m datetime\u001b[39m.\u001b[39mnow() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m time_start \u001b[39m+\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecs_total):\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:685\u001b[0m, in \u001b[0;36mEAGGA.run_cv\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    682\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m    683\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m--> 685\u001b[0m model, stop_epoch, stop_secs, stopped_early, losses_stop_early \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(optimizer, loss_fn, model, dataset_train, dataset_stop_early)\n\u001b[0;32m    687\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mperformance\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(loss_fn, model, dataset_val))\n\u001b[0;32m    688\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mperformance\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlosses_stop_early\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m losses_stop_early\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:718\u001b[0m, in \u001b[0;36mEAGGA.train\u001b[1;34m(self, optimizer, loss_fn, model, dataset_train, dataset_stop_early)\u001b[0m\n\u001b[0;32m    715\u001b[0m model\u001b[39m.\u001b[39mtrain()  \u001b[39m# training mode, put here as we switch to eval mode at the end of each epoch in def stop_early\u001b[39;00m\n\u001b[0;32m    716\u001b[0m running_epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 718\u001b[0m \u001b[39mfor\u001b[39;49;00m batch_input, batch_target \u001b[39min\u001b[39;49;00m loader_train:  \u001b[39m# divide data in mini batches\u001b[39;49;00m\n\u001b[0;32m    719\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()  \u001b[39m# set gradients to 0\u001b[39;49;00m\n\u001b[0;32m    720\u001b[0m     batch_output \u001b[39m=\u001b[39;49m model(\u001b[39m*\u001b[39;49mbatch_input)\u001b[39m.\u001b[39;49mflatten()  \u001b[39m# expand batch_input as it is a list of tuples (Dataset getter splits according to group structure)\u001b[39;49;00m\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:763\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 763\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    764\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:698\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 698\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:347\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39mwhile\u001b[39;00m batch:\n\u001b[0;32m    346\u001b[0m     \u001b[39myield\u001b[39;00m batch\n\u001b[1;32m--> 347\u001b[0m     batch \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39mitertools\u001b[39m.\u001b[39mislice(sampler_iter, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)]\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:199\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[0;32m    198\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m--> 199\u001b[0m \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39mtolist()[\n\u001b[0;32m    200\u001b[0m     : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n\n\u001b[0;32m    201\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 100,\n",
    "    'lambda': 10,\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "patience = 100\n",
    "\n",
    "secs_per_fold = 60\n",
    "secs_total = 8 * 60 * 60\n",
    "\n",
    "pareto_fronts = list()\n",
    "for (oml_dataset, class_positive) in zip(oml_datasets[:1], positive_classes[:1]):  # TODO: remove [:1]\n",
    "    name = oml_dataset.name\n",
    "    print(f'Dataset {name}')\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    #eagga.load_population(3)\n",
    "    \n",
    "    pareto_front = eagga.run_eagga()\n",
    "    pareto_fronts.append(pareto_front)\n",
    "pareto_fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
