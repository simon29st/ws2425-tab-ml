{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\\n%pip install openml\\n%pip install numpy\\n%pip install pandas\\n# cf. https://pytorch.org/get-started/locally/\\n#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\\n%pip install -U scikit-learn\\n%pip install scipy\\n%pip install -U pymoo\\n%pip list'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\n",
    "%pip install openml\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# cf. https://pytorch.org/get-started/locally/\n",
    "#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\n",
    "%pip install -U scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -U pymoo\n",
    "%pip list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diabetes\n",
      "Starting init population\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished init population\n",
      "Start EAGGA at 2025-03-02T23:45:58.867458\n",
      "Generation 1, evaluate 15 individuals\n",
      "Running 5-fold CV for individual: 6 total layers, 3 nodes per hidden layer, gs: ([2, 5, 6], [[[0, 1, 3, 4, 7], 1]])\n",
      "Fold 1/5 | trained for 424 epochs | stopped early: True | metrics: {'loss': 0.4880519360303879, 'auc': np.float64(0.8702321724709785), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 372 epochs | stopped early: True | metrics: {'loss': 0.520868569612503, 'auc': np.float64(0.8101160862354893), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 285 epochs | stopped early: True | metrics: {'loss': 0.5162191092967987, 'auc': np.float64(0.8618336886993603), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 286 epochs | stopped early: True | metrics: {'loss': 0.5475216507911682, 'auc': np.float64(0.7386363636363636), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 246 epochs | stopped early: True | metrics: {'loss': 0.6601495444774628, 'auc': np.float64(0.5), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 3 total layers, 3 nodes per hidden layer, gs: ([0, 1, 3, 4, 6, 7], [[[2, 5], 1]])\n",
      "Fold 1/5 | trained for 192 epochs | stopped early: True | metrics: {'loss': 0.6342396140098572, 'auc': np.float64(0.7408789386401327), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 2 epochs | stopped early: True | metrics: {'loss': 0.6104214787483215, 'auc': np.float64(0.685737976782753), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 790 epochs | stopped early: True | metrics: {'loss': 0.6055173575878143, 'auc': np.float64(0.6904051172707889), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 95 epochs | stopped early: True | metrics: {'loss': 0.6488947570323944, 'auc': np.float64(0.5513468013468013), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 457 epochs | stopped early: True | metrics: {'loss': 0.5981501340866089, 'auc': np.float64(0.6603535353535352), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 6 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 0]])\n",
      "Fold 1/5 | trained for 251 epochs | stopped early: True | metrics: {'loss': 0.47288699448108673, 'auc': np.float64(0.8530265339966833), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 315 epochs | stopped early: True | metrics: {'loss': 0.6350431442260742, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 218 epochs | stopped early: True | metrics: {'loss': 0.653149425983429, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 341 epochs | stopped early: True | metrics: {'loss': 0.5548380613327026, 'auc': np.float64(0.7586279461279462), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 318 epochs | stopped early: True | metrics: {'loss': 0.5382642447948456, 'auc': np.float64(0.8127104377104377), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 7 total layers, 4 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Fold 1/5 | trained for 357 epochs | stopped early: True | metrics: {'loss': 0.4710480272769928, 'auc': np.float64(0.8478441127694859), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 303 epochs | stopped early: True | metrics: {'loss': 0.5547218322753906, 'auc': np.float64(0.7508291873963516), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 306 epochs | stopped early: True | metrics: {'loss': 0.5309969484806061, 'auc': np.float64(0.7665245202558635), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 456 epochs | stopped early: True | metrics: {'loss': 0.5291696786880493, 'auc': np.float64(0.785563973063973), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 223 epochs | stopped early: True | metrics: {'loss': 0.44353674352169037, 'auc': np.float64(0.8600589225589226), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([2, 3, 4, 5, 6, 7], [[[0, 1], 0]])\n",
      "Fold 1/5 | trained for 468 epochs | stopped early: True | metrics: {'loss': 0.4767606556415558, 'auc': np.float64(0.8138474295190713), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 2/5 | trained for 2 epochs | stopped early: True | metrics: {'loss': 0.6462030410766602, 'auc': np.float64(0.5), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 3/5 | trained for 126 epochs | stopped early: True | metrics: {'loss': 0.5466440916061401, 'auc': np.float64(0.785501066098081), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 4/5 | trained for 358 epochs | stopped early: True | metrics: {'loss': 0.6513029038906097, 'auc': np.float64(0.5), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 5/5 | trained for 107 epochs | stopped early: True | metrics: {'loss': 0.6624772250652313, 'auc': np.float64(0.5), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Running 5-fold CV for individual: 3 total layers, 3 nodes per hidden layer, gs: ([0, 1, 3, 4, 5, 6, 7], [[[2], 0]])\n",
      "Fold 1/5 | trained for 166 epochs | stopped early: True | metrics: {'loss': 0.6654944121837616, 'auc': np.float64(0.3567578772802653), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 6 epochs | stopped early: True | metrics: {'loss': 0.6429421603679657, 'auc': np.float64(0.46102819237147596), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 54 epochs | stopped early: True | metrics: {'loss': 0.6467209160327911, 'auc': np.float64(0.4869936034115138), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 46 epochs | stopped early: True | metrics: {'loss': 0.653835654258728, 'auc': np.float64(0.34953703703703703), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 379 epochs | stopped early: True | metrics: {'loss': 0.6513630449771881, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([0, 2, 3, 4, 6, 7], [[[1, 5], 0]])\n",
      "Fold 1/5 | trained for 617 epochs | stopped early: True | metrics: {'loss': 0.5584745407104492, 'auc': np.float64(0.7761194029850746), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 2/5 | trained for 489 epochs | stopped early: True | metrics: {'loss': 0.5185574293136597, 'auc': np.float64(0.7719734660033167), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 3/5 | trained for 426 epochs | stopped early: True | metrics: {'loss': 0.5688141882419586, 'auc': np.float64(0.7155650319829424), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 4/5 | trained for 127 epochs | stopped early: True | metrics: {'loss': 0.6420314013957977, 'auc': np.float64(0.5288299663299663), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 5/5 | trained for 479 epochs | stopped early: True | metrics: {'loss': 0.5192351043224335, 'auc': np.float64(0.9457070707070707), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Running 5-fold CV for individual: 4 total layers, 3 nodes per hidden layer, gs: ([0, 1, 3, 4, 5, 6, 7], [[[2], 0]])\n",
      "Fold 1/5 | trained for 207 epochs | stopped early: True | metrics: {'loss': 0.6526918411254883, 'auc': np.float64(0.41500829187396354), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 94 epochs | stopped early: True | metrics: {'loss': 0.645746648311615, 'auc': np.float64(0.5053897180762853), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 209 epochs | stopped early: True | metrics: {'loss': 0.6485719084739685, 'auc': np.float64(0.3545842217484009), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 171 epochs | stopped early: True | metrics: {'loss': 0.6650089919567108, 'auc': np.float64(0.30892255892255893), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 1057 epochs | stopped early: False | metrics: {'loss': 0.6419920325279236, 'auc': np.float64(0.4421296296296297), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 4 total layers, 3 nodes per hidden layer, gs: ([2, 3, 4, 6, 7], [[[0, 5], 1], [[1], 1]])\n",
      "Fold 1/5 | trained for 287 epochs | stopped early: True | metrics: {'loss': 0.4455680102109909, 'auc': np.float64(0.8698175787728026), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 293 epochs | stopped early: True | metrics: {'loss': 0.5382156074047089, 'auc': np.float64(0.7757048092868988), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 289 epochs | stopped early: True | metrics: {'loss': 0.5751245617866516, 'auc': np.float64(0.7134328358208956), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 423 epochs | stopped early: True | metrics: {'loss': 0.497133269906044, 'auc': np.float64(0.7912457912457912), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 295 epochs | stopped early: True | metrics: {'loss': 0.5285289883613586, 'auc': np.float64(0.7857744107744108), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 4 nodes per hidden layer, gs: ([0, 2, 3, 4, 6, 7], [[[1, 5], 1]])\n",
      "Fold 1/5 | trained for 178 epochs | stopped early: True | metrics: {'loss': 0.6451626121997833, 'auc': np.float64(0.5), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 572 epochs | stopped early: True | metrics: {'loss': 0.4876137524843216, 'auc': np.float64(0.8146766169154229), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 487 epochs | stopped early: True | metrics: {'loss': 0.530532643198967, 'auc': np.float64(0.7778251599147121), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 268 epochs | stopped early: True | metrics: {'loss': 0.4874260872602463, 'auc': np.float64(0.8005050505050504), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 333 epochs | stopped early: True | metrics: {'loss': 0.44057703018188477, 'auc': np.float64(0.9191919191919192), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([3, 4, 6, 7], [[[0, 1], 1], [[2], 1], [[5], 1]])\n",
      "Fold 1/5 | trained for 106 epochs | stopped early: True | metrics: {'loss': 0.6525303721427917, 'auc': np.float64(0.3994610281923715), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 166 epochs | stopped early: True | metrics: {'loss': 0.5417456328868866, 'auc': np.float64(0.7927031509121061), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 254 epochs | stopped early: True | metrics: {'loss': 0.45827996730804443, 'auc': np.float64(0.8353944562899787), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 395 epochs | stopped early: True | metrics: {'loss': 0.4299079179763794, 'auc': np.float64(0.8531144781144782), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 417 epochs | stopped early: False | metrics: {'loss': 0.4705573469400406, 'auc': np.float64(0.8404882154882155), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([0, 2, 4, 6], [[[3, 5, 7], 0], [[1], 0]])\n",
      "Fold 1/5 | trained for 58 epochs | stopped early: True | metrics: {'loss': 0.6719468533992767, 'auc': np.float64(0.7989220563847429), 'nf': 0.5, 'ni': 0.10714285714285714, 'nnm': 0.5}\n",
      "Fold 2/5 | trained for 301 epochs | stopped early: True | metrics: {'loss': 0.5497242212295532, 'auc': np.float64(0.7458540630182421), 'nf': 0.5, 'ni': 0.10714285714285714, 'nnm': 0.5}\n",
      "Fold 3/5 | trained for 221 epochs | stopped early: True | metrics: {'loss': 0.5581165552139282, 'auc': np.float64(0.7688699360341152), 'nf': 0.5, 'ni': 0.10714285714285714, 'nnm': 0.5}\n",
      "Fold 4/5 | trained for 2 epochs | stopped early: True | metrics: {'loss': 0.6765425205230713, 'auc': np.float64(0.39330808080808083), 'nf': 0.5, 'ni': 0.10714285714285714, 'nnm': 0.5}\n",
      "Fold 5/5 | trained for 204 epochs | stopped early: True | metrics: {'loss': 0.6038885712623596, 'auc': np.float64(0.7213804713804712), 'nf': 0.5, 'ni': 0.10714285714285714, 'nnm': 0.5}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 5, 6], [[[7], 0]])\n",
      "Fold 1/5 | trained for 1157 epochs | stopped early: False | metrics: {'loss': 0.6286525130271912, 'auc': np.float64(0.6689469320066334), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 589 epochs | stopped early: True | metrics: {'loss': 0.6113040447235107, 'auc': np.float64(0.7516583747927031), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 378 epochs | stopped early: True | metrics: {'loss': 0.6265497505664825, 'auc': np.float64(0.6906183368869936), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 114 epochs | stopped early: True | metrics: {'loss': 0.6316489279270172, 'auc': np.float64(0.731060606060606), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 161 epochs | stopped early: True | metrics: {'loss': 0.6435257196426392, 'auc': np.float64(0.5784932659932659), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 5, 6], [[[7], 0]])\n",
      "Fold 1/5 | trained for 145 epochs | stopped early: True | metrics: {'loss': 0.654279500246048, 'auc': np.float64(0.3424543946932007), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 482 epochs | stopped early: True | metrics: {'loss': 0.6344124674797058, 'auc': np.float64(0.7541459369817579), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 449 epochs | stopped early: True | metrics: {'loss': 0.6351136863231659, 'auc': np.float64(0.6571428571428571), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 265 epochs | stopped early: True | metrics: {'loss': 0.6265669465065002, 'auc': np.float64(0.6321548821548821), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 419 epochs | stopped early: True | metrics: {'loss': 0.6201140582561493, 'auc': np.float64(0.6893939393939393), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([1, 2, 3, 5, 6, 7], [[[0, 4], 0]])\n",
      "Fold 1/5 | trained for 190 epochs | stopped early: True | metrics: {'loss': 0.5967373847961426, 'auc': np.float64(0.6438640132669984), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 2/5 | trained for 22 epochs | stopped early: True | metrics: {'loss': 0.6565536260604858, 'auc': np.float64(0.5634328358208954), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 3/5 | trained for 325 epochs | stopped early: True | metrics: {'loss': 0.6353309452533722, 'auc': np.float64(0.5776119402985075), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 4/5 | trained for 261 epochs | stopped early: True | metrics: {'loss': 0.6434185802936554, 'auc': np.float64(0.5300925925925926), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Fold 5/5 | trained for 159 epochs | stopped early: True | metrics: {'loss': 0.654608279466629, 'auc': np.float64(0.599537037037037), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "\n",
      "Compiled modules for significant speedup can not be used!\n",
      "https://pymoo.org/installation.html#installation\n",
      "\n",
      "To disable this warning:\n",
      "from pymoo.config import Config\n",
      "Config.warnings['not_compiled'] = False\n",
      "\n",
      "Dominated Hypervolume: 0.7831924534328044 for Pareto front [[0.19783586 0.125      0.         0.        ]\n",
      " [0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 1 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 2, evaluate 5 individuals\n",
      "Running 5-fold CV for individual: 5 total layers, 4 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Fold 1/5 | trained for 358 epochs | stopped early: True | metrics: {'loss': 0.5579942464828491, 'auc': np.float64(0.7128938640132669), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 295 epochs | stopped early: True | metrics: {'loss': 0.574345588684082, 'auc': np.float64(0.7858623548922056), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 492 epochs | stopped early: True | metrics: {'loss': 0.48543645441532135, 'auc': np.float64(0.8081023454157783), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 222 epochs | stopped early: True | metrics: {'loss': 0.6517456471920013, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 435 epochs | stopped early: True | metrics: {'loss': 0.5222452878952026, 'auc': np.float64(0.7803030303030303), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 7 total layers, 4 nodes per hidden layer, gs: ([0, 4, 6, 7, 3], [[[5, 2, 1], 1]])\n",
      "Fold 1/5 | trained for 333 epochs | stopped early: True | metrics: {'loss': 0.4771336019039154, 'auc': np.float64(0.814262023217247), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 666 epochs | stopped early: True | metrics: {'loss': 0.6358192265033722, 'auc': np.float64(0.43076285240464346), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 272 epochs | stopped early: True | metrics: {'loss': 0.6479499936103821, 'auc': np.float64(0.5846481876332623), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 94 epochs | stopped early: True | metrics: {'loss': 0.6597898900508881, 'auc': np.float64(0.3598484848484848), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 18 epochs | stopped early: True | metrics: {'loss': 0.6601293683052063, 'auc': np.float64(0.23737373737373738), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 4 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 0]])\n",
      "Fold 1/5 | trained for 396 epochs | stopped early: True | metrics: {'loss': 0.4904889464378357, 'auc': np.float64(0.8327114427860697), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 184 epochs | stopped early: True | metrics: {'loss': 0.51814304292202, 'auc': np.float64(0.8005804311774462), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 205 epochs | stopped early: True | metrics: {'loss': 0.4680792987346649, 'auc': np.float64(0.8744136460554371), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 127 epochs | stopped early: True | metrics: {'loss': 0.5768661797046661, 'auc': np.float64(0.7337962962962963), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 187 epochs | stopped early: True | metrics: {'loss': 0.6079438030719757, 'auc': np.float64(0.7598905723905723), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 6 total layers, 3 nodes per hidden layer, gs: ([0, 2, 4, 7], [[[1, 5, 3, 6], 1]])\n",
      "Fold 1/5 | trained for 419 epochs | stopped early: True | metrics: {'loss': 0.6421104073524475, 'auc': np.float64(0.5), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 737 epochs | stopped early: True | metrics: {'loss': 0.4320738911628723, 'auc': np.float64(0.8640132669983416), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 588 epochs | stopped early: True | metrics: {'loss': 0.4285537004470825, 'auc': np.float64(0.8631130063965885), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 244 epochs | stopped early: True | metrics: {'loss': 0.5454432666301727, 'auc': np.float64(0.8278619528619529), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 71 epochs | stopped early: True | metrics: {'loss': 0.6512166261672974, 'auc': np.float64(0.38804713804713803), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([0, 3, 4, 6, 7], [[[1], 0], [[2, 5], 1]])\n",
      "Fold 1/5 | trained for 223 epochs | stopped early: True | metrics: {'loss': 0.6229905784130096, 'auc': np.float64(0.5366915422885572), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Fold 2/5 | trained for 168 epochs | stopped early: True | metrics: {'loss': 0.5815680623054504, 'auc': np.float64(0.6679104477611939), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Fold 3/5 | trained for 299 epochs | stopped early: True | metrics: {'loss': 0.5388808250427246, 'auc': np.float64(0.7799573560767591), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Fold 4/5 | trained for 299 epochs | stopped early: True | metrics: {'loss': 0.6284235715866089, 'auc': np.float64(0.6906565656565657), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Fold 5/5 | trained for 673 epochs | stopped early: False | metrics: {'loss': 0.5155220329761505, 'auc': np.float64(0.845959595959596), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Dominated Hypervolume: 0.7831924534328044 for Pareto front [[0.19783586 0.125      0.         0.        ]\n",
      " [0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 2 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 3, evaluate 5 individuals\n",
      "Running 5-fold CV for individual: 6 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Fold 1/5 | trained for 285 epochs | stopped early: True | metrics: {'loss': 0.5436430871486664, 'auc': np.float64(0.7624378109452737), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 70 epochs | stopped early: True | metrics: {'loss': 0.6459109783172607, 'auc': np.float64(0.20812603648424546), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 3/5 | trained for 285 epochs | stopped early: True | metrics: {'loss': 0.6463795304298401, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 4/5 | trained for 72 epochs | stopped early: True | metrics: {'loss': 0.6506431102752686, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 5/5 | trained for 339 epochs | stopped early: True | metrics: {'loss': 0.4428495764732361, 'auc': np.float64(0.8722643097643097), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 4 nodes per hidden layer, gs: ([0, 3, 4, 7, 2, 5, 6], [[[1], 1]])\n",
      "Fold 1/5 | trained for 343 epochs | stopped early: True | metrics: {'loss': 0.5133869647979736, 'auc': np.float64(0.7860696517412935), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Fold 2/5 | trained for 410 epochs | stopped early: True | metrics: {'loss': 0.5155511200428009, 'auc': np.float64(0.7997512437810945), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m\n\u001b[0;32m     23\u001b[0m eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     24\u001b[0m     oml_dataset\u001b[39m=\u001b[39moml_dataset,\n\u001b[0;32m     25\u001b[0m     class_positive\u001b[39m=\u001b[39mclass_positive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     file_path\u001b[39m=\u001b[39mfile_path\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[39m#eagga.load_population(6)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m pareto_front \u001b[39m=\u001b[39m eagga\u001b[39m.\u001b[39;49mrun_eagga()\n\u001b[0;32m     36\u001b[0m pareto_fronts\u001b[39m.\u001b[39mappend(pareto_front)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:588\u001b[0m, in \u001b[0;36mEAGGA.run_eagga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGeneration \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, evaluate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring)\u001b[39m}\u001b[39;00m\u001b[39m individuals\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring:\n\u001b[1;32m--> 588\u001b[0m     individual[\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_cv(individual)\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation\u001b[39m.\u001b[39mappend(individual)\n\u001b[0;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m datetime\u001b[39m.\u001b[39mnow() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m time_start \u001b[39m+\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecs_total):\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:685\u001b[0m, in \u001b[0;36mEAGGA.run_cv\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    682\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m    683\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m--> 685\u001b[0m model, stop_epoch, stopped_early \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(optimizer, loss_fn, model, dataset_train, dataset_stop_early)\n\u001b[0;32m    687\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mperformance\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(loss_fn, model, dataset_val))\n\u001b[0;32m    688\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(stop_epoch)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:718\u001b[0m, in \u001b[0;36mEAGGA.train\u001b[1;34m(self, optimizer, loss_fn, model, dataset_train, dataset_stop_early)\u001b[0m\n\u001b[0;32m    715\u001b[0m running_epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    717\u001b[0m \u001b[39mfor\u001b[39;00m batch_input, batch_target \u001b[39min\u001b[39;00m loader_train:  \u001b[39m# divide data in mini batches\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()  \u001b[39m# set gradients to 0\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     batch_output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39mbatch_input)\u001b[39m.\u001b[39mflatten()  \u001b[39m# expand batch_input as it is a list of tuples (Dataset getter splits according to group structure)\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     batch_loss \u001b[39m=\u001b[39m loss_fn(batch_output, batch_target)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[39m.\u001b[39m__dynamo_disable \u001b[39m=\u001b[39m disable_fn\n\u001b[1;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m disable_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[39m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[0;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[0;32m    743\u001b[0m )\n\u001b[0;32m    744\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    746\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:970\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    968\u001b[0m     per_device_and_dtype_grads \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 970\u001b[0m \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_zero_grad_profile_name):\n\u001b[0;32m    971\u001b[0m     \u001b[39mfor\u001b[39;49;00m group \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_groups:\n\u001b[0;32m    972\u001b[0m         \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m group[\u001b[39m\"\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:769\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting():\n\u001b[0;32m    768\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m--> 769\u001b[0m         torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_exit\u001b[39m.\u001b[39;49m_RecordFunction(record)\n\u001b[0;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_ops.py:960\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[0;32m    959\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch_in_python(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fallthrough_keys())\n\u001b[1;32m--> 960\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 100,\n",
    "    'lambda': 10,\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "patience = 100\n",
    "\n",
    "secs_per_fold = 60\n",
    "secs_total = 8 * 60 * 60\n",
    "\n",
    "pareto_fronts = list()\n",
    "for (oml_dataset, class_positive) in zip(oml_datasets[:1], positive_classes[:1]):  # TODO: remove [:1]\n",
    "    name = oml_dataset.name\n",
    "    print(f'Dataset {name}')\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    #eagga.load_population(6)\n",
    "    \n",
    "    pareto_front = eagga.run_eagga()\n",
    "    pareto_fronts.append(pareto_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
