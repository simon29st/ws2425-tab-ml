{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\\n%pip install openml\\n%pip install numpy\\n%pip install pandas\\n# cf. https://pytorch.org/get-started/locally/\\n#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\\n%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\\n%pip install -U scikit-learn\\n%pip install scipy\\n%pip install -U pymoo\\n%pip list'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\n",
    "%pip install openml\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# cf. https://pytorch.org/get-started/locally/\n",
    "#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\n",
    "%pip install -U scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -U pymoo\n",
    "%pip list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(359955, 'blood-transfusion-service-center', '2', (748, 5)), (10093, 'banknote-authentication', '2', (1372, 5)), (146820, 'wilt', '2', (4839, 6)), (168350, 'phoneme', '2', (5404, 6)), (37, 'diabetes', 'tested_positive', (768, 9)), (146819, 'climate-model-simulation-crashes', '1', (540, 19)), (359972, 'sylvine', '1', (5124, 21)), (3913, 'kc2', 'yes', (522, 22)), (3918, 'pc1', True, (1109, 22)), (359962, 'kc1', True, (2109, 22)), (3904, 'jm1', True, (10885, 22)), (167120, 'numerai28.6', '1', (96320, 22)), (9946, 'wdbc', '2', (569, 31)), (359975, 'Satellite', 'Anomaly', (5100, 37)), (3903, 'pc3', True, (1563, 38)), (43, 'spambase', '1', (4601, 58)), (190137, 'ozone-level-8hr', '2', (2534, 73)), (190392, 'madeline', '1', (3140, 260)), (190410, 'philippine', '1', (5832, 309)), (189922, 'gina', '1', (3153, 971))]\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']\n",
    "\n",
    "zipped = list(zip(oml_task_ids, oml_datasets, positive_classes))\n",
    "zipped = sorted(zipped, key=lambda item: (item[1].get_data()[0].shape[1], item[1].get_data()[0].shape[0]))  # order ascending by # of features, tiebreaker is # of samples\n",
    "print([(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance 1: [(359955, 'blood-transfusion-service-center', '2', (748, 5)), (146819, 'climate-model-simulation-crashes', '1', (540, 19)), (3904, 'jm1', True, (10885, 22)), (43, 'spambase', '1', (4601, 58))]\n",
      "instance 2: [(10093, 'banknote-authentication', '2', (1372, 5)), (359972, 'sylvine', '1', (5124, 21)), (167120, 'numerai28.6', '1', (96320, 22)), (190137, 'ozone-level-8hr', '2', (2534, 73))]\n",
      "instance 3: [(146820, 'wilt', '2', (4839, 6)), (3913, 'kc2', 'yes', (522, 22)), (9946, 'wdbc', '2', (569, 31)), (190392, 'madeline', '1', (3140, 260))]\n",
      "instance 4: [(168350, 'phoneme', '2', (5404, 6)), (3918, 'pc1', True, (1109, 22)), (359975, 'Satellite', 'Anomaly', (5100, 37)), (190410, 'philippine', '1', (5832, 309))]\n",
      "instance 5: [(37, 'diabetes', 'tested_positive', (768, 9)), (359962, 'kc1', True, (2109, 22)), (3903, 'pc3', True, (1563, 38)), (189922, 'gina', '1', (3153, 971))]\n",
      "20\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "zipped_instance_1 = zipped[::5]\n",
    "zipped_instance_2 = zipped[1::5]\n",
    "zipped_instance_3 = zipped[2::5]\n",
    "zipped_instance_4 = zipped[3::5]\n",
    "zipped_instance_5 = zipped[4::5]\n",
    "\n",
    "print('instance 1:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_1])\n",
    "print('instance 2:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_2])\n",
    "print('instance 3:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_3])\n",
    "print('instance 4:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_4])\n",
    "print('instance 5:', [(id, ds.name, class_pos, ds.get_data()[0].shape) for id, ds, class_pos in zipped_instance_5])\n",
    "\n",
    "# verify that all 20 are included\n",
    "zipped_instances_union = set.union(\n",
    "    set(ds.name for _, ds, _ in zipped_instance_1),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_2),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_3),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_4),\n",
    "    set(ds.name for _, ds, _ in zipped_instance_5)\n",
    ")\n",
    "print(len(zipped_instances_union))\n",
    "print(zipped_instances_union == set(ds.name for _, ds, _ in zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset blood-transfusion-service-center\n",
      "Dataset blood-transfusion-service-center\n",
      "Starting init population\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished init population\n",
      "Start EAGGA at 2025-03-06T18:16:42.897636\n",
      "Generation 1, evaluate 100 individuals\n",
      "Running 5-fold CV for individual 1/100: 3 total layers, 4 nodes per hidden layer, dropout p 0.2, gs: ([1, 2, 3], [[[0], 1]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     26\u001b[0m     eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     27\u001b[0m         oml_dataset\u001b[39m=\u001b[39moml_dataset,\n\u001b[0;32m     28\u001b[0m         class_positive\u001b[39m=\u001b[39mclass_positive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m         file_path\u001b[39m=\u001b[39mfile_path\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m     \u001b[39m#eagga.load_population(0)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     pareto_front \u001b[39m=\u001b[39m eagga\u001b[39m.\u001b[39;49mrun_eagga()\n\u001b[0;32m     40\u001b[0m     pareto_fronts\u001b[39m.\u001b[39mappend(pareto_front)\n\u001b[0;32m     41\u001b[0m pareto_fronts\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:640\u001b[0m, in \u001b[0;36mEAGGA.run_eagga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m logging\u001b[39m.\u001b[39minfo(msg)\n\u001b[0;32m    639\u001b[0m \u001b[39mprint\u001b[39m(msg)\n\u001b[1;32m--> 640\u001b[0m individual[\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_cv(individual)\n\u001b[0;32m    641\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation\u001b[39m.\u001b[39mappend(individual)\n\u001b[0;32m    643\u001b[0m \u001b[39mif\u001b[39;00m datetime\u001b[39m.\u001b[39mnow() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m time_start \u001b[39m+\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecs_total):\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:740\u001b[0m, in \u001b[0;36mEAGGA.run_cv\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    724\u001b[0m dataset_val \u001b[39m=\u001b[39m Dataset(\n\u001b[0;32m    725\u001b[0m     X\u001b[39m=\u001b[39mdata_val\u001b[39m.\u001b[39mloc[:, data_val\u001b[39m.\u001b[39mcolumns \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_column],\n\u001b[0;32m    726\u001b[0m     y\u001b[39m=\u001b[39mdata_val\u001b[39m.\u001b[39mloc[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_column],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    729\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_cuda\n\u001b[0;32m    730\u001b[0m )\n\u001b[0;32m    732\u001b[0m model \u001b[39m=\u001b[39m NeuralNetwork(\n\u001b[0;32m    733\u001b[0m     group_structure\u001b[39m=\u001b[39mgroup_structure,\n\u001b[0;32m    734\u001b[0m     output_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,  \u001b[39m# we only use binary datasets\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    737\u001b[0m     p_dropout\u001b[39m=\u001b[39mp_dropout\n\u001b[0;32m    738\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_cuda)\n\u001b[1;32m--> 740\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdamW(model\u001b[39m.\u001b[39;49mparameters())\n\u001b[0;32m    741\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m    743\u001b[0m model, stop_epoch, stop_secs, stopped_early, losses_stop_early \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain(optimizer, loss_fn, model, dataset_train, dataset_stop_early)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\adamw.py:100\u001b[0m, in \u001b[0;36mAdamW.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTensor betas[1] must be 1-element\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m     89\u001b[0m     lr\u001b[39m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m     betas\u001b[39m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     fused\u001b[39m=\u001b[39mfused,\n\u001b[0;32m     99\u001b[0m )\n\u001b[1;32m--> 100\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:377\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    374\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: param_groups}]\n\u001b[0;32m    376\u001b[0m \u001b[39mfor\u001b[39;00m param_group \u001b[39min\u001b[39;00m param_groups:\n\u001b[1;32m--> 377\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_param_group(cast(\u001b[39mdict\u001b[39;49m, param_group))\n\u001b[0;32m    379\u001b[0m \u001b[39m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m disable_fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fn, \u001b[39m\"\u001b[39m\u001b[39m__dynamo_disable\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m disable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[39m.\u001b[39m__dynamo_disable \u001b[39m=\u001b[39m disable_fn\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mcallback\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mguards\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m GlobalStateGuard\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msymbolic_convert\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TensorifyState\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_guards\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_logging\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m structured\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexc\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TensorifyScalarRestartAnalysis\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_guards\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tracing, TracingContext\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m config, exc, logging \u001b[39mas\u001b[39;00m torchdynamo_logging, trace_rules, variables\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbytecode_analysis\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     get_indexof,\n\u001b[0;32m     33\u001b[0m     JUMP_OPNAMES,\n\u001b[0;32m     34\u001b[0m     livevars_analysis,\n\u001b[0;32m     35\u001b[0m     propagate_line_nums,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbytecode_transformation\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m     cleaned_instructions,\n\u001b[0;32m     39\u001b[0m     create_call_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     unique_id,\n\u001b[0;32m     47\u001b[0m )\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mresume_execution\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     BuiltinVariable,\n\u001b[0;32m     48\u001b[0m     FunctionalCallVariable,\n\u001b[0;32m     49\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[0;32m     50\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     51\u001b[0m     PolyfilledFunctionVariable,\n\u001b[0;32m     52\u001b[0m     SkipFunctionVariable,\n\u001b[0;32m     53\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[0;32m     54\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     55\u001b[0m     UserMethodVariable,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     59\u001b[0m np: Optional[types\u001b[39m.\u001b[39mModuleType] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:109\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39msdpa\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m SDPAParamsVariable\n\u001b[0;32m    100\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m     DataPtrVariable,\n\u001b[0;32m    102\u001b[0m     FakeItemVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     UntypedStorageVariable,\n\u001b[0;32m    108\u001b[0m )\n\u001b[1;32m--> 109\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TorchCtxManagerClassVariable, TorchInGraphFunctionVariable\n\u001b[0;32m    110\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39muser_defined\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    111\u001b[0m     MutableMappingVariable,\n\u001b[0;32m    112\u001b[0m     RemovableHandleVariable,\n\u001b[0;32m    113\u001b[0m     UserDefinedClassVariable,\n\u001b[0;32m    114\u001b[0m     UserDefinedObjectVariable,\n\u001b[0;32m    115\u001b[0m )\n\u001b[0;32m    118\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m    119\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAutogradFunctionContextVariable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    120\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAutogradFunctionVariable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWithExitFunctionVariable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    185\u001b[0m ]\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_python_dispatch\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m is_traceable_wrapper_subclass_type\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m config, polyfills, variables\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcodegen\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m PyCodegen\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcreate_parameter_op\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     can_convert_to_tracable_parameter,\n\u001b[0;32m     22\u001b[0m     new_parameter_placeholder,\n\u001b[0;32m     23\u001b[0m     tracable_create_parameter,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdevice_interface\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m get_registered_device_interfaces\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\codegen.py:35\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn_module\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m NNModuleVariable\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     NumpyNdarrayVariable,\n\u001b[0;32m     31\u001b[0m     SymNodeVariable,\n\u001b[0;32m     32\u001b[0m     TensorVariable,\n\u001b[0;32m     33\u001b[0m     UnspecializedPythonVariable,\n\u001b[0;32m     34\u001b[0m )\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch_function\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m TensorWithTFOverrideVariable\n\u001b[0;32m     38\u001b[0m \u001b[39m@dataclasses\u001b[39m\u001b[39m.\u001b[39mdataclass\n\u001b[0;32m     39\u001b[0m \u001b[39mclass\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mGraphOutputEntry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     index: \u001b[39mint\u001b[39m\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch_function.py:185\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[39mif\u001b[39;00m most_recent_func \u001b[39m!=\u001b[39m BUILTIN_TO_TENSOR_FN_MAP[op]:\n\u001b[0;32m    182\u001b[0m                     BUILTIN_TO_TENSOR_RFN_MAP[op] \u001b[39m=\u001b[39m most_recent_func\n\u001b[1;32m--> 185\u001b[0m populate_builtin_to_tensor_fn_map()\n\u001b[0;32m    187\u001b[0m banned_attrs \u001b[39m=\u001b[39m [\n\u001b[0;32m    188\u001b[0m     fn\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    189\u001b[0m     \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m get_default_nowrap_functions()\n\u001b[0;32m    190\u001b[0m     \u001b[39mif\u001b[39;00m is_tensor_base_attr_getter(fn)\n\u001b[0;32m    191\u001b[0m ]\n\u001b[0;32m    194\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mget_prev_stack_var_name\u001b[39m():\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch_function.py:160\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m setup_fn, op_list \u001b[39min\u001b[39;00m setups_and_oplists:\n\u001b[0;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m op_list:\n\u001b[1;32m--> 160\u001b[0m         setup_fn(op)\n\u001b[0;32m    161\u001b[0m         \u001b[39massert\u001b[39;00m most_recent_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    162\u001b[0m         BUILTIN_TO_TENSOR_FN_MAP[op] \u001b[39m=\u001b[39m most_recent_func\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch_function.py:156\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map.<locals>.<lambda>\u001b[1;34m(o)\u001b[0m\n\u001b[0;32m    149\u001b[0m inp1_int \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32)\n\u001b[0;32m    150\u001b[0m \u001b[39mwith\u001b[39;00m GetMethodMode():\n\u001b[0;32m    151\u001b[0m     setups_and_oplists \u001b[39m=\u001b[39m [\n\u001b[0;32m    152\u001b[0m         (\u001b[39mlambda\u001b[39;00m o: o(inp0), un_ops),\n\u001b[0;32m    153\u001b[0m         (\u001b[39mlambda\u001b[39;00m o: o(inp0_int), un_int_ops),\n\u001b[0;32m    154\u001b[0m         (\u001b[39mlambda\u001b[39;00m o: o(inp0, inp1), bin_ops),\n\u001b[0;32m    155\u001b[0m         (\u001b[39mlambda\u001b[39;00m o: o(inp0_int, inp1_int), bin_int_ops),\n\u001b[1;32m--> 156\u001b[0m         (\u001b[39mlambda\u001b[39;00m o: o(inp0_int, \u001b[39m0\u001b[39;49m), tensor_and_int_ops),\n\u001b[0;32m    157\u001b[0m     ]\n\u001b[0;32m    158\u001b[0m     \u001b[39mfor\u001b[39;00m setup_fn, op_list \u001b[39min\u001b[39;00m setups_and_oplists:\n\u001b[0;32m    159\u001b[0m         \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m op_list:\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\torch_function.py:144\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map.<locals>.GetMethodMode.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mnonlocal\u001b[39;00m most_recent_func\n\u001b[0;32m    143\u001b[0m most_recent_func \u001b[39m=\u001b[39m func\n\u001b[1;32m--> 144\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 100,\n",
    "    'lambda': 10,\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "min_epochs = 200\n",
    "patience = 100\n",
    "\n",
    "secs_per_fold = 2 * 60\n",
    "secs_total = 8 * 60 * 60\n",
    "\n",
    "pareto_fronts = list()\n",
    "for (_, oml_dataset, class_positive) in zipped_instance_2:\n",
    "    name = oml_dataset.name\n",
    "    msg = f'Dataset {name}'\n",
    "    print(msg)\n",
    "    logging.info(msg)\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        min_epochs=min_epochs,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    #eagga.load_population(0)\n",
    "    \n",
    "    pareto_front = eagga.run_eagga()\n",
    "    pareto_fronts.append(pareto_front)\n",
    "pareto_fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
