{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diabetes\n",
      "Starting init population\n",
      "Finished init population\n",
      "Loaded population + offspring from file, discarded previous population + offspring\n",
      "Start EAGGA at 2025-03-02T16:46:22.533047\n",
      "Generation 8, evaluate 5 individuals\n",
      "Running 5-fold CV for individual: 3 total layers, 5 nodes per hidden layer, gs: ([5, 0], [[[7, 3, 6, 2], 0], [[4, 1], 0]])\n",
      "Stop early: 0.6918844272692998 < 0.6950320998827616, epoch stop: 25\n",
      "Fold 1/5 | trained for 25 epochs | metrics: {'loss': 0.6582106096403939, 'auc': np.float64(0.6011608623548922), 'nf': 0.75, 'ni': 0.25, 'nnm': 0.75}\n",
      "Stop early: 0.6545081049203872 < 0.656075249115626, epoch stop: 6\n",
      "Fold 2/5 | trained for 6 epochs | metrics: {'loss': 0.6634176458631244, 'auc': np.float64(0.2777777777777778), 'nf': 0.75, 'ni': 0.25, 'nnm': 0.75}\n",
      "Stop early: 0.6029110103845596 < 0.6246581921974818, epoch stop: 23\n",
      "Fold 3/5 | trained for 23 epochs | metrics: {'loss': 0.6030165212494987, 'auc': np.float64(0.6946695095948827), 'nf': 0.75, 'ni': 0.25, 'nnm': 0.75}\n",
      "Stop early: 0.6627619256575902 < 0.6635981798171997, epoch stop: 48\n",
      "Fold 4/5 | trained for 48 epochs | metrics: {'loss': 0.6631401010922023, 'auc': np.float64(0.5425084175084175), 'nf': 0.75, 'ni': 0.25, 'nnm': 0.75}\n",
      "Stop early: 0.6233178704977036 < 0.6317224701245626, epoch stop: 11\n",
      "Fold 5/5 | trained for 11 epochs | metrics: {'loss': 0.6420379025595528, 'auc': np.float64(0.6553030303030304), 'nf': 0.75, 'ni': 0.25, 'nnm': 0.75}\n",
      "Running 5-fold CV for individual: 4 total layers, 10 nodes per hidden layer, gs: ([1, 3, 2, 7], [[[0, 5, 4, 6], 0]])\n",
      "Stop early: 0.6532966981331507 < 0.6604981422424316, epoch stop: 16\n",
      "Fold 1/5 | trained for 16 epochs | metrics: {'loss': 0.6093527632100242, 'auc': np.float64(0.6310116086235489), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.5}\n",
      "Stop early: 0.6471809685230254 < 0.6472065846125284, epoch stop: 18\n",
      "Fold 2/5 | trained for 18 epochs | metrics: {'loss': 0.7111702476228986, 'auc': np.float64(0.5190713101160862), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.5}\n",
      "Stop early: 0.6944104005893073 < 0.6991279025872549, epoch stop: 12\n",
      "Fold 3/5 | trained for 12 epochs | metrics: {'loss': 0.6153126614434379, 'auc': np.float64(0.5893390191897654), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.5}\n",
      "Stop early: 0.66446965833505 < 0.6977095504601797, epoch stop: 12\n",
      "Fold 4/5 | trained for 12 epochs | metrics: {'loss': 0.6334046125411987, 'auc': np.float64(0.5921717171717171), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.5}\n",
      "Stop early: 0.7013563781976699 < 0.7225456635157267, epoch stop: 1\n",
      "Fold 5/5 | trained for 1 epochs | metrics: {'loss': 0.6237391914640155, 'auc': np.float64(0.6043771043771045), 'nf': 0.5, 'ni': 0.21428571428571427, 'nnm': 0.5}\n",
      "Running 5-fold CV for individual: 3 total layers, 5 nodes per hidden layer, gs: ([0], [[[6, 2], 1], [[3], 0], [[5, 4], 1], [[7, 1], 0]])\n",
      "Stop early: 0.7103591322898865 < 0.710517555475235, epoch stop: 28\n",
      "Fold 1/5 | trained for 28 epochs | metrics: {'loss': 0.6081989705562592, 'auc': np.float64(0.6919568822553898), 'nf': 0.875, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.691953107714653 < 0.6944785316785177, epoch stop: 16\n",
      "Fold 2/5 | trained for 16 epochs | metrics: {'loss': 0.7104912400245667, 'auc': np.float64(0.48009950248756217), 'nf': 0.875, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.7200270722309747 < 0.7536573708057404, epoch stop: 17\n",
      "Fold 3/5 | trained for 17 epochs | metrics: {'loss': 0.6322528209005084, 'auc': np.float64(0.4980810234541577), 'nf': 0.875, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6782668362061182 < 0.6846061448256174, epoch stop: 12\n",
      "Fold 4/5 | trained for 12 epochs | metrics: {'loss': 0.6554719720567975, 'auc': np.float64(0.4162457912457912), 'nf': 0.875, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.5992855817079544 < 0.606834868590037, epoch stop: 13\n",
      "Fold 5/5 | trained for 13 epochs | metrics: {'loss': 0.7175870026860919, 'auc': np.float64(0.5736531986531986), 'nf': 0.875, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Running 5-fold CV for individual: 4 total layers, 8 nodes per hidden layer, gs: ([6, 3, 2], [[[7, 5, 1, 0, 4], 0]])\n",
      "Stop early: 0.6612090706825257 < 0.6613388359546661, epoch stop: 16\n",
      "Fold 1/5 | trained for 16 epochs | metrics: {'loss': 0.643915057182312, 'auc': np.float64(0.6546434494195688), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.625}\n",
      "Stop early: 0.6664032042026521 < 0.6678309539953867, epoch stop: 5\n",
      "Fold 2/5 | trained for 5 epochs | metrics: {'loss': 0.646711928503854, 'auc': np.float64(0.5182421227197347), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.625}\n",
      "Stop early: 0.6758243381977082 < 0.6804004609584808, epoch stop: 23\n",
      "Fold 3/5 | trained for 23 epochs | metrics: {'loss': 0.6098364889621735, 'auc': np.float64(0.6515991471215352), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.625}\n",
      "Stop early: 0.6556280642747878 < 0.6591420869032542, epoch stop: 8\n",
      "Fold 4/5 | trained for 8 epochs | metrics: {'loss': 0.6392978812967028, 'auc': np.float64(0.5134680134680134), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.625}\n",
      "Stop early: 0.7170282562573751 < 0.7178143858909607, epoch stop: 10\n",
      "Fold 5/5 | trained for 10 epochs | metrics: {'loss': 0.6470798168863569, 'auc': np.float64(0.4749579124579124), 'nf': 0.625, 'ni': 0.35714285714285715, 'nnm': 0.625}\n",
      "Running 5-fold CV for individual: 3 total layers, 3 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 5, 6, 7], [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\nn\\init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     22\u001b[0m eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     23\u001b[0m     oml_dataset\u001b[39m=\u001b[39moml_dataset,\n\u001b[0;32m     24\u001b[0m     class_positive\u001b[39m=\u001b[39mclass_positive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     file_path\u001b[39m=\u001b[39mfile_path\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m eagga\u001b[39m.\u001b[39mload_population(\u001b[39m6\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m eagga\u001b[39m.\u001b[39;49mrun_eagga()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:583\u001b[0m, in \u001b[0;36mEAGGA.run_eagga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGeneration \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, evaluate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring)\u001b[39m}\u001b[39;00m\u001b[39m individuals\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    582\u001b[0m \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring:\n\u001b[1;32m--> 583\u001b[0m     individual[\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_cv(individual)\n\u001b[0;32m    584\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation\u001b[39m.\u001b[39mappend(individual)\n\u001b[0;32m    586\u001b[0m     \u001b[39mif\u001b[39;00m datetime\u001b[39m.\u001b[39mnow() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m time_start \u001b[39m+\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecs_total):\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:672\u001b[0m, in \u001b[0;36mEAGGA.run_cv\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    669\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m    670\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m--> 672\u001b[0m model, stop_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(optimizer, loss_fn, model, dataset_train, dataset_stop_early)\n\u001b[0;32m    674\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mperformance\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(loss_fn, model, dataset_val))\n\u001b[0;32m    675\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(stop_epoch)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:705\u001b[0m, in \u001b[0;36mEAGGA.train\u001b[1;34m(self, optimizer, loss_fn, model, dataset_train, dataset_stop_early)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mfor\u001b[39;00m batch_input, batch_target \u001b[39min\u001b[39;00m loader_train:  \u001b[39m# divide data in mini batches\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# set gradients to 0\u001b[39;00m\n\u001b[1;32m--> 705\u001b[0m     batch_output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mbatch_input)\u001b[39m.\u001b[39mflatten()  \u001b[39m# expand batch_input as it is a list of tuples (Dataset getter splits according to group structure)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     batch_loss \u001b[39m=\u001b[39m loss_fn(batch_output, batch_target)\n\u001b[0;32m    708\u001b[0m     running_epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:61\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, *xs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(xs):\n\u001b[0;32m     60\u001b[0m     output_networks\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetworks[i](x))\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_out(torch\u001b[39m.\u001b[39;49mcat(output_networks, \u001b[39m1\u001b[39;49m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 15,  # TODO: 100\n",
    "    'lambda': 5,  # TODO: 10\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 16\n",
    "patience = 10\n",
    "\n",
    "secs_per_fold = 30\n",
    "secs_total = 20 * 60\n",
    "\n",
    "for (oml_dataset, class_positive) in zip(oml_datasets[:1], positive_classes[:1]):  # TODO: remove [:1]\n",
    "    name = oml_dataset.name\n",
    "    print(f'Dataset {name}')\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    eagga.load_population(6)\n",
    "    eagga.run_eagga()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
