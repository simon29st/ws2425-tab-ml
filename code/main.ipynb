{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "import torch\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from classes import Dataset, GroupStructure, WeightClipper\n",
    "from functions import run_HPO_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_task_diabetes = tasks.get_task(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, categorical_indicator, attribute_names = oml_task_diabetes.get_dataset().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg   plas  pres  skin   insu  mass   pedi   age            class\n",
       "0     6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  tested_positive\n",
       "1     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  tested_negative\n",
       "2     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  tested_positive\n",
       "3     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  tested_negative\n",
       "4     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  tested_positive\n",
       "..    ...    ...   ...   ...    ...   ...    ...   ...              ...\n",
       "763  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0  tested_negative\n",
       "764   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0  tested_negative\n",
       "765   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0  tested_negative\n",
       "766   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0  tested_positive\n",
       "767   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0  tested_negative\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GroupStructure(\n",
    "    {0, 1, 2, 3, 4, 5, 6, 7},\n",
    "    {0, 1},\n",
    "    ((2, 5), 1),\n",
    "    ((4,), 0),\n",
    "    ((7, 3, 6), 1)\n",
    ")\n",
    "\n",
    "tmp = Dataset(\n",
    "    X=Xy.loc[:, Xy.columns != 'class'],\n",
    "    y=Xy.loc[:, 'class'],\n",
    "    class_pos='tested_positive',\n",
    "    group_structure=gs\n",
    ")\n",
    "len(tmp)\n",
    "tmp[2]\n",
    "\n",
    "gs.get_unconstrained_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False, False, True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running HPO: 3 total_layers, 3 nodes per hidden layer\n",
      "fold 1 / 5\n",
      "epoch 0 / 10, eval loss 2.3989868611097336\n",
      "epoch 1 / 10, train loss 1.5397669478104665\n",
      "epoch 1 / 10, eval loss 1.3948207600758626\n",
      "epoch 2 / 10, train loss 0.9595855548977852\n",
      "epoch 2 / 10, eval loss 0.860941258760599\n",
      "epoch 3 / 10, train loss 0.7439251106518966\n",
      "epoch 3 / 10, eval loss 0.7051993104127737\n",
      "epoch 4 / 10, train loss 0.6811506496025965\n",
      "epoch 4 / 10, eval loss 0.6609895779536321\n",
      "epoch 5 / 10, train loss 0.6630716811005886\n",
      "epoch 5 / 10, eval loss 0.649787024809764\n",
      "epoch 6 / 10, train loss 0.659400252195505\n",
      "epoch 6 / 10, eval loss 0.6486282967604123\n",
      "epoch 7 / 10, train loss 0.658531744319659\n",
      "epoch 7 / 10, eval loss 0.6477387020221124\n",
      "epoch 8 / 10, train loss 0.6570493487211374\n",
      "epoch 8 / 10, eval loss 0.6468521769230182\n",
      "epoch 9 / 10, train loss 0.656177349961721\n",
      "epoch 9 / 10, eval loss 0.6463244832479037\n",
      "epoch 10 / 10, train loss 0.655495072213503\n",
      "epoch 10 / 10, eval loss 0.6458642138884618\n",
      "(0.5538971807628524, 0.75, 0.14285714285714285, 0.125)\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.5409, 0.0000],\n",
      "        [0.4063, 0.0000],\n",
      "        [0.0000, 0.1060]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[2.1610e-01, 0.0000e+00, 1.8831e-03],\n",
      "        [3.3217e-04, 1.1458e-03, 3.6986e-01],\n",
      "        [5.2985e-02, 2.5021e-01, 1.9308e-02]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.2470],\n",
      "        [ 0.7534],\n",
      "        [ 0.4347]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[-0.5017, -0.3632, -0.3523],\n",
      "        [ 0.1947,  0.3280, -0.5784],\n",
      "        [ 0.2366, -0.1841, -0.0795]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.3042, 0.0000, 0.4080],\n",
      "        [0.0368, 0.3509, 0.0094],\n",
      "        [0.0000, 0.3760, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0065, 0.4136],\n",
      "        [0.0000, 0.4567, 0.0010],\n",
      "        [0.0272, 0.5119, 0.1959]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 2 / 5\n",
      "epoch 0 / 10, eval loss 3.4597331698124227\n",
      "epoch 1 / 10, train loss 2.477365622153649\n",
      "epoch 1 / 10, eval loss 2.297580911562993\n",
      "epoch 2 / 10, train loss 1.5126926457652679\n",
      "epoch 2 / 10, eval loss 1.4390625541026776\n",
      "epoch 3 / 10, train loss 1.0632183907123713\n",
      "epoch 3 / 10, eval loss 1.2067688199189992\n",
      "epoch 4 / 10, train loss 0.9413000906889255\n",
      "epoch 4 / 10, eval loss 1.0648938371584966\n",
      "epoch 5 / 10, train loss 0.8753952699211928\n",
      "epoch 5 / 10, eval loss 0.9771326230122492\n",
      "epoch 6 / 10, train loss 0.8336449936032295\n",
      "epoch 6 / 10, eval loss 0.9180416464805603\n",
      "epoch 7 / 10, train loss 0.8050641692601718\n",
      "epoch 7 / 10, eval loss 0.8758968344101539\n",
      "epoch 8 / 10, train loss 0.7842187130680451\n",
      "epoch 8 / 10, eval loss 0.8442291342295133\n",
      "epoch 9 / 10, train loss 0.7680561336187216\n",
      "epoch 9 / 10, eval loss 0.8194165734144357\n",
      "epoch 10 / 10, train loss 0.7550030654439559\n",
      "epoch 10 / 10, eval loss 0.7994661720899435\n",
      "(0.2810945273631841, 0.75, 0.14285714285714285, 0.125)\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 0.3369],\n",
      "        [0.5911, 0.3193]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.3391, 0.2316, 0.1180],\n",
      "        [0.1996, 0.0593, 0.0000],\n",
      "        [0.0000, 0.4117, 0.4005]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.6175],\n",
      "        [-0.3097],\n",
      "        [ 0.1689]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.6449,  0.7460, -0.5232],\n",
      "        [ 0.1298,  0.0928,  0.0949],\n",
      "        [-0.1835,  0.1475, -0.5547]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.4291, 0.0000],\n",
      "        [0.3371, 0.0513, 0.0005],\n",
      "        [0.0000, 0.0000, 0.1362]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.0612],\n",
      "        [0.0000, 0.0000, 0.0122],\n",
      "        [0.0000, 0.5177, 0.1565]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 3 / 5\n",
      "epoch 0 / 10, eval loss 0.6614143550395966\n",
      "epoch 1 / 10, train loss 0.669545418367936\n",
      "epoch 1 / 10, eval loss 0.6783200869193444\n",
      "epoch 2 / 10, train loss 0.6730627045035362\n",
      "epoch 2 / 10, eval loss 0.6472877653745505\n",
      "epoch 3 / 10, train loss 0.6757330304154983\n",
      "epoch 3 / 10, eval loss 0.6502959086344793\n",
      "epoch 4 / 10, train loss 0.6732329955467811\n",
      "epoch 4 / 10, eval loss 0.6503996298863337\n",
      "epoch 5 / 10, train loss 0.6714726193593099\n",
      "epoch 5 / 10, eval loss 0.6503544587355393\n",
      "epoch 6 / 10, train loss 0.6703106537461281\n",
      "epoch 6 / 10, eval loss 0.6503101105873401\n",
      "epoch 7 / 10, train loss 0.6693420352844092\n",
      "epoch 7 / 10, eval loss 0.6502700195862696\n",
      "epoch 8 / 10, train loss 0.6685056078892487\n",
      "epoch 8 / 10, eval loss 0.6502557053015783\n",
      "epoch 9 / 10, train loss 0.6677234837642083\n",
      "epoch 9 / 10, eval loss 0.6501985834195063\n",
      "epoch 10 / 10, train loss 0.6670023873448372\n",
      "epoch 10 / 10, eval loss 0.6501336235266465\n",
      "(0.4422174840085288, 0.75, 0.14285714285714285, 0.125)\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.6132, 0.0000],\n",
      "        [0.2481, 0.2617],\n",
      "        [0.4056, 0.0000]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.0671],\n",
      "        [0.0083, 0.0219, 0.0089],\n",
      "        [0.4821, 0.3423, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.8409],\n",
      "        [-0.2874],\n",
      "        [ 0.4512]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[ 0.2952,  0.5453, -0.3763],\n",
      "        [ 0.4004,  0.4321, -0.1739],\n",
      "        [ 0.1558,  0.5078, -0.4682]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.2377],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.4392, 0.0000, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.3172, 0.0262, 0.0000],\n",
      "        [0.1092, 0.0431, 0.0000],\n",
      "        [0.0656, 0.0000, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 4 / 5\n",
      "epoch 0 / 10, eval loss 0.7297558142588689\n",
      "epoch 1 / 10, train loss 0.6845571880157177\n",
      "epoch 1 / 10, eval loss 0.6815380041415875\n",
      "epoch 2 / 10, train loss 0.6653236391452643\n",
      "epoch 2 / 10, eval loss 0.6683513063650864\n",
      "epoch 3 / 10, train loss 0.6617940979508253\n",
      "epoch 3 / 10, eval loss 0.6626430474794828\n",
      "epoch 4 / 10, train loss 0.6590739253621835\n",
      "epoch 4 / 10, eval loss 0.659250415288485\n",
      "epoch 5 / 10, train loss 0.6576765609475282\n",
      "epoch 5 / 10, eval loss 0.657051180417721\n",
      "epoch 6 / 10, train loss 0.656781344459607\n",
      "epoch 6 / 10, eval loss 0.655451394044436\n",
      "epoch 7 / 10, train loss 0.6561483276578096\n",
      "epoch 7 / 10, eval loss 0.6541791764589456\n",
      "epoch 8 / 10, train loss 0.655631908430503\n",
      "epoch 8 / 10, eval loss 0.6531605651745429\n",
      "epoch 9 / 10, train loss 0.6551922559738159\n",
      "epoch 9 / 10, eval loss 0.6522876505668347\n",
      "epoch 10 / 10, train loss 0.65479993304381\n",
      "epoch 10 / 10, eval loss 0.6514971210406377\n",
      "(0.542929292929293, 0.75, 0.14285714285714285, 0.125)\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.4306, 0.0000],\n",
      "        [0.0000, 0.0051],\n",
      "        [0.4500, 0.0000]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[5.3730e-01, 1.5645e-04, 1.2006e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4595e-01, 3.1729e-02, 0.0000e+00]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.5013],\n",
      "        [-0.1439],\n",
      "        [-0.6149]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[-0.0833,  0.0935,  0.3443],\n",
      "        [-0.4958,  0.3715, -0.0350],\n",
      "        [-0.5390,  0.0851,  0.1545]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0012, 0.3729, 0.0285],\n",
      "        [0.0000, 0.4821, 0.0000],\n",
      "        [0.5752, 0.0000, 0.0033]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.4221, 0.2126, 0.0190],\n",
      "        [0.3026, 0.4134, 0.0000],\n",
      "        [0.3266, 0.4822, 0.0243]], requires_grad=True) torch.Size([3, 3])\n",
      "fold 5 / 5\n",
      "epoch 0 / 10, eval loss 4.139919076974575\n",
      "epoch 1 / 10, train loss 3.414790546664825\n",
      "epoch 1 / 10, eval loss 2.9861154602124143\n",
      "epoch 2 / 10, train loss 2.4746804048235598\n",
      "epoch 2 / 10, eval loss 2.1432212728720446\n",
      "epoch 3 / 10, train loss 1.810670944933708\n",
      "epoch 3 / 10, eval loss 1.5527535952054536\n",
      "epoch 4 / 10, train loss 1.355569956967464\n",
      "epoch 4 / 10, eval loss 1.154068600672942\n",
      "epoch 5 / 10, train loss 1.0438057952202284\n",
      "epoch 5 / 10, eval loss 0.8921294854237483\n",
      "epoch 6 / 10, train loss 0.834820273403938\n",
      "epoch 6 / 10, eval loss 0.7360568367517911\n",
      "epoch 7 / 10, train loss 0.7152942373202398\n",
      "epoch 7 / 10, eval loss 0.6755419556911175\n",
      "epoch 8 / 10, train loss 0.6711549117014959\n",
      "epoch 8 / 10, eval loss 0.6711893861110394\n",
      "epoch 9 / 10, train loss 0.6611470276346574\n",
      "epoch 9 / 10, eval loss 0.6727821505986727\n",
      "epoch 10 / 10, train loss 0.6576390954164358\n",
      "epoch 10 / 10, eval loss 0.6725604259050809\n",
      "(0.4604377104377105, 0.75, 0.14285714285714285, 0.125)\n",
      "NeuralNetwork(\n",
      "  (networks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer_out): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n",
      "Network 1\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0860, 0.2159],\n",
      "        [0.4895, 0.4767],\n",
      "        [0.0000, 0.0000]], requires_grad=True) torch.Size([3, 2])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0689, 0.2084, 0.0000],\n",
      "        [0.0259, 0.0491, 0.2340]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 2\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[-0.3821],\n",
      "        [ 0.4655],\n",
      "        [-0.1430]], requires_grad=True) torch.Size([3, 1])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[-0.0424,  0.3049,  0.3621],\n",
      "        [ 0.1044, -0.5517,  0.0303],\n",
      "        [ 0.3853,  0.3193,  0.3041]], requires_grad=True) torch.Size([3, 3])\n",
      "Network 3\n",
      "Layer 1\n",
      "Parameter containing:\n",
      "tensor([[0.0041, 0.0000, 0.1027],\n",
      "        [0.0100, 0.0000, 0.1002],\n",
      "        [0.0000, 0.0000, 0.0000]], requires_grad=True) torch.Size([3, 3])\n",
      "Layer 3\n",
      "Parameter containing:\n",
      "tensor([[0.1316, 0.0000, 0.5203],\n",
      "        [0.0537, 0.5092, 0.0000],\n",
      "        [0.3585, 0.0209, 0.0000]], requires_grad=True) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# outer\n",
    "data_train_test, data_val = train_test_split(\n",
    "    Xy,\n",
    "    train_size=2/3,\n",
    "    shuffle=True,\n",
    "    stratify=Xy.loc[:, 'class']\n",
    ")\n",
    "\n",
    "# reset indices as StratifiedKFold assumes 0-(n-1) index\n",
    "data_train_test = data_train_test.reset_index(drop=True)\n",
    "data_val = data_val.reset_index(drop=True)\n",
    "\n",
    "# inner\n",
    "cv_inner = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=False  # TODO: set to True\n",
    ")\n",
    "\n",
    "'''\n",
    "in each inner fold, run EAGGA + find an optimal pareto front of configurations for this specific fold\n",
    "then in the outer fold (holdout), compare each fold-specific optimal pareto front + select optimum\n",
    "'''\n",
    "monotonicity_weight_clipper = WeightClipper(0, None)  # enforce monotonicity by clipping weights to [0, infty) after each epoch (in def train)\n",
    "run_HPO_CV(cv_inner, data_train_test, epochs=10, batch_size=8, weight_clipper=monotonicity_weight_clipper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
