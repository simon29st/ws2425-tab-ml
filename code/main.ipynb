{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Das System kann die angegebene Datei nicht finden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openml in .\\.venv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in .\\.venv\\lib\\site-packages (from openml) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in .\\.venv\\lib\\site-packages (from openml) (0.14.2)\n",
      "Requirement already satisfied: requests in .\\.venv\\lib\\site-packages (from openml) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in .\\.venv\\lib\\site-packages (from openml) (1.6.1)\n",
      "Requirement already satisfied: python-dateutil in .\\.venv\\lib\\site-packages (from openml) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in .\\.venv\\lib\\site-packages (from openml) (2.2.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in .\\.venv\\lib\\site-packages (from openml) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.6.2 in .\\.venv\\lib\\site-packages (from openml) (2.2.3)\n",
      "Requirement already satisfied: minio in .\\.venv\\lib\\site-packages (from openml) (7.2.15)\n",
      "Requirement already satisfied: pyarrow in .\\.venv\\lib\\site-packages (from openml) (19.0.1)\n",
      "Requirement already satisfied: tqdm in .\\.venv\\lib\\site-packages (from openml) (4.67.1)\n",
      "Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from openml) (24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas>=1.0.0->openml) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas>=1.0.0->openml) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil->openml) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in .\\.venv\\lib\\site-packages (from scikit-learn>=0.18->openml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in .\\.venv\\lib\\site-packages (from scikit-learn>=0.18->openml) (3.5.0)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from minio->openml) (2025.1.31)\n",
      "Requirement already satisfied: urllib3 in .\\.venv\\lib\\site-packages (from minio->openml) (2.3.0)\n",
      "Requirement already satisfied: argon2-cffi in .\\.venv\\lib\\site-packages (from minio->openml) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in .\\.venv\\lib\\site-packages (from minio->openml) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in .\\.venv\\lib\\site-packages (from minio->openml) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests->openml) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests->openml) (3.10)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm->openml) (0.4.6)\n",
      "Requirement already satisfied: argon2-cffi-bindings in .\\.venv\\lib\\site-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in .\\.venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.17.1)\n",
      "Requirement already satisfied: pycparser in .\\.venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in .\\.venv\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in .\\.venv\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in .\\.venv\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in .\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in .\\.venv\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in .\\.venv\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in .\\.venv\\lib\\site-packages (from scipy) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymoo in .\\.venv\\lib\\site-packages (0.6.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in .\\.venv\\lib\\site-packages (from pymoo) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.1 in .\\.venv\\lib\\site-packages (from pymoo) (1.15.2)\n",
      "Requirement already satisfied: matplotlib>=3 in .\\.venv\\lib\\site-packages (from pymoo) (3.10.1)\n",
      "Requirement already satisfied: autograd>=1.4 in .\\.venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
      "Requirement already satisfied: cma==3.2.2 in .\\.venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
      "Requirement already satisfied: alive-progress in .\\.venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
      "Requirement already satisfied: dill in .\\.venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
      "Requirement already satisfied: Deprecated in .\\.venv\\lib\\site-packages (from pymoo) (1.2.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
      "Requirement already satisfied: about-time==4.2.1 in .\\.venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
      "Requirement already satisfied: grapheme==0.6.0 in .\\.venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in .\\.venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Package              Version\n",
      "-------------------- -----------\n",
      "about-time           4.2.1\n",
      "alive-progress       3.2.0\n",
      "argon2-cffi          23.1.0\n",
      "argon2-cffi-bindings 21.2.0\n",
      "asttokens            3.0.0\n",
      "autograd             1.7.0\n",
      "certifi              2025.1.31\n",
      "cffi                 1.17.1\n",
      "charset-normalizer   3.4.1\n",
      "cma                  3.2.2\n",
      "colorama             0.4.6\n",
      "comm                 0.2.2\n",
      "contourpy            1.3.1\n",
      "cramjam              2.9.1\n",
      "cycler               0.12.1\n",
      "deap                 1.4.2\n",
      "debugpy              1.8.12\n",
      "decorator            5.1.1\n",
      "Deprecated           1.2.18\n",
      "dill                 0.3.9\n",
      "executing            2.2.0\n",
      "fastparquet          2024.11.0\n",
      "filelock             3.17.0\n",
      "fonttools            4.56.0\n",
      "fsspec               2025.2.0\n",
      "grapheme             0.6.0\n",
      "idna                 3.10\n",
      "ipykernel            6.29.5\n",
      "ipython              8.32.0\n",
      "jedi                 0.19.2\n",
      "Jinja2               3.1.5\n",
      "joblib               1.4.2\n",
      "jupyter_client       8.6.3\n",
      "jupyter_core         5.7.2\n",
      "kiwisolver           1.4.8\n",
      "liac-arff            2.5.0\n",
      "MarkupSafe           3.0.2\n",
      "matplotlib           3.10.1\n",
      "matplotlib-inline    0.1.7\n",
      "minio                7.2.15\n",
      "mpmath               1.3.0\n",
      "nds                  0.4.3\n",
      "nest-asyncio         1.6.0\n",
      "networkx             3.4.2\n",
      "numpy                2.2.3\n",
      "openml               0.15.1\n",
      "packaging            24.2\n",
      "pandas               2.2.3\n",
      "parso                0.8.4\n",
      "pillow               11.1.0\n",
      "pip                  25.0.1\n",
      "platformdirs         4.3.6\n",
      "prompt_toolkit       3.0.50\n",
      "psutil               7.0.0\n",
      "pure_eval            0.2.3\n",
      "pyarrow              19.0.1\n",
      "pycparser            2.22\n",
      "pycryptodome         3.21.0\n",
      "Pygments             2.19.1\n",
      "pymoo                0.6.1.3\n",
      "pyparsing            3.2.1\n",
      "python-dateutil      2.9.0.post0\n",
      "pytz                 2025.1\n",
      "pywin32              308\n",
      "pyzmq                26.2.1\n",
      "requests             2.32.3\n",
      "scikit-learn         1.6.1\n",
      "scipy                1.15.2\n",
      "setuptools           75.8.0\n",
      "six                  1.17.0\n",
      "stack-data           0.6.3\n",
      "sympy                1.13.1\n",
      "threadpoolctl        3.5.0\n",
      "torch                2.6.0\n",
      "torchaudio           2.6.0\n",
      "torchvision          0.21.0\n",
      "tornado              6.4.2\n",
      "tqdm                 4.67.1\n",
      "traitlets            5.14.3\n",
      "typing_extensions    4.12.2\n",
      "tzdata               2025.1\n",
      "urllib3              2.3.0\n",
      "wcwidth              0.2.13\n",
      "wrapt                1.17.2\n",
      "xmltodict            0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setuptools==70.3.0  # apparently setuptools < 71.0.0 is required for a required package of openml to install on here\n",
    "%pip install openml\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "# cf. https://pytorch.org/get-started/locally/\n",
    "#%pip install torch torchvision torchaudio  # cuda 12.4, cf. nvidia-smi shell command\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # cpu version\n",
    "%pip install -U scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -U pymoo\n",
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import tasks\n",
    "\n",
    "from classes import EAGGA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:372: UserWarning: `download_data` will default to False starting in 0.16. Please set `download_data` explicitly to suppress this warning.\n",
      "  warnings.warn(\n",
      "f:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\openml\\tasks\\functions.py:380: UserWarning: `download_qualities` will default to False starting in 0.16. Please set `download_qualities` explicitly to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oml_task_ids = [37, 43, 3903, 3904, 3913, 3918, 10093, 9946, 146819, 359955, 189922, 359962, 190392, 167120, 190137, 190410, 168350, 359975, 359972, 146820]\n",
    "oml_tasks = tasks.get_tasks(oml_task_ids)\n",
    "\n",
    "oml_datasets = [oml_task.get_dataset() for oml_task in oml_tasks]\n",
    "\n",
    "# define positive classes\n",
    "positive_classes = ['tested_positive', '1', True, True, 'yes', True, '2', '2', '1', '2', '1', True, '1', '1', '2', '1', '2', 'Anomaly', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diabetes\n",
      "Starting init population\n",
      "Finished init population\n",
      "Start EAGGA at 2025-03-02T23:16:51.014690\n",
      "Generation 1, evaluate 5 individuals\n",
      "Running 5-fold CV for individual: 4 total layers, 3 nodes per hidden layer, gs: ([0, 2, 4, 6, 7], [[[1, 3, 5], 0]])\n",
      "Stop early: 0.6568940788507461 < 0.6568993628025055\n",
      "Fold 1/5 | trained for 48 epochs | stopped early: True | metrics: {'loss': 0.6401613354682922, 'auc': np.float64(0.4937810945273632), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6463037222623825 < 0.6465589106082916\n",
      "Fold 2/5 | trained for 195 epochs | stopped early: True | metrics: {'loss': 0.6715280413627625, 'auc': np.float64(0.4112769485903814), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6864931672811508 < 0.6866236329078674\n",
      "Fold 3/5 | trained for 55 epochs | stopped early: True | metrics: {'loss': 0.7076503038406372, 'auc': np.float64(0.2298507462686567), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.635211831331253 < 0.6355190873146057\n",
      "Fold 4/5 | trained for 16 epochs | stopped early: True | metrics: {'loss': 0.6431586146354675, 'auc': np.float64(0.7032828282828283), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6104459375143051 < 0.6104762554168701\n",
      "Fold 5/5 | trained for 133 epochs | stopped early: True | metrics: {'loss': 0.609898179769516, 'auc': np.float64(0.7462121212121212), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Running 5-fold CV for individual: 3 total layers, 4 nodes per hidden layer, gs: ([1, 2, 3, 4, 5, 6], [[[0, 7], 0]])\n",
      "Stop early: 0.6322778701782227 < 0.6323634684085846\n",
      "Fold 1/5 | trained for 30 epochs | stopped early: True | metrics: {'loss': 0.6489887833595276, 'auc': np.float64(0.3343698175787728), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Stop early: 0.7196766883134842 < 0.7210446000099182\n",
      "Fold 2/5 | trained for 24 epochs | stopped early: True | metrics: {'loss': 0.6891426742076874, 'auc': np.float64(0.37873134328358204), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Stop early: 0.674739933013916 < 0.6751611530780792\n",
      "Fold 3/5 | trained for 62 epochs | stopped early: True | metrics: {'loss': 0.6853668391704559, 'auc': np.float64(0.2712153518123668), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Stop early: 0.6925250709056854 < 0.6928537786006927\n",
      "Fold 4/5 | trained for 41 epochs | stopped early: True | metrics: {'loss': 0.6669871509075165, 'auc': np.float64(0.40635521885521886), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Stop early: 0.6754882216453553 < 0.6755037605762482\n",
      "Fold 5/5 | trained for 27 epochs | stopped early: True | metrics: {'loss': 0.6513120234012604, 'auc': np.float64(0.5), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.25}\n",
      "Running 5-fold CV for individual: 4 total layers, 4 nodes per hidden layer, gs: ([0, 1, 2, 3, 4, 5, 6], [[[7], 0]])\n",
      "Stop early: 0.6452303439378738 < 0.6452470123767853\n",
      "Fold 1/5 | trained for 48 epochs | stopped early: True | metrics: {'loss': 0.6513316333293915, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Stop early: 0.6498136192560195 < 0.6502038836479187\n",
      "Fold 2/5 | trained for 225 epochs | stopped early: True | metrics: {'loss': 0.6362793445587158, 'auc': np.float64(0.6737147595356552), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Stop early: 0.6671218127012253 < 0.6672718226909637\n",
      "Fold 3/5 | trained for 30 epochs | stopped early: True | metrics: {'loss': 0.6450668275356293, 'auc': np.float64(0.33219616204690827), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Stop early: 0.6589273810386658 < 0.6627850532531738\n",
      "Fold 4/5 | trained for 10 epochs | stopped early: True | metrics: {'loss': 0.6865748167037964, 'auc': np.float64(0.31923400673400676), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Stop early: 0.5873823672533035 < 0.5875668525695801\n",
      "Fold 5/5 | trained for 340 epochs | stopped early: True | metrics: {'loss': 0.6074315905570984, 'auc': np.float64(0.7007575757575758), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 3 total layers, 8 nodes per hidden layer, gs: ([0, 2, 3, 4, 6], [[[5, 7], 1], [[1], 1]])\n",
      "Stop early: 0.6830218255519866 < 0.6917922496795654\n",
      "Fold 1/5 | trained for 49 epochs | stopped early: True | metrics: {'loss': 0.6836729645729065, 'auc': np.float64(0.36442786069651745), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6773486763238907 < 0.6960282921791077\n",
      "Fold 2/5 | trained for 23 epochs | stopped early: True | metrics: {'loss': 0.6700936853885651, 'auc': np.float64(0.6330845771144279), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6556463897228241 < 0.6755819618701935\n",
      "Fold 3/5 | trained for 11 epochs | stopped early: True | metrics: {'loss': 0.6581985354423523, 'auc': np.float64(0.4831556503198294), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6746458768844604 < 0.6853671371936798\n",
      "Fold 4/5 | trained for 54 epochs | stopped early: True | metrics: {'loss': 0.6988090872764587, 'auc': np.float64(0.3236531986531986), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6724897086620331 < 0.6770530343055725\n",
      "Fold 5/5 | trained for 49 epochs | stopped early: True | metrics: {'loss': 0.6476174592971802, 'auc': np.float64(0.6203703703703703), 'nf': 0.375, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.645205843448639 < 0.6452364325523376\n",
      "Fold 1/5 | trained for 52 epochs | stopped early: True | metrics: {'loss': 0.6257889270782471, 'auc': np.float64(0.7802653399668324), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6331033617258072 < 0.6350688934326172\n",
      "Fold 2/5 | trained for 15 epochs | stopped early: True | metrics: {'loss': 0.6570258140563965, 'auc': np.float64(0.7294776119402986), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6464267402887345 < 0.6470385193824768\n",
      "Fold 3/5 | trained for 13 epochs | stopped early: True | metrics: {'loss': 0.6375894546508789, 'auc': np.float64(0.805543710021322), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6579954564571381 < 0.6580058038234711\n",
      "Fold 4/5 | trained for 199 epochs | stopped early: True | metrics: {'loss': 0.6520269811153412, 'auc': np.float64(0.20833333333333331), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6786956578493119 < 0.6787107288837433\n",
      "Fold 5/5 | trained for 47 epochs | stopped early: True | metrics: {'loss': 0.6693563461303711, 'auc': np.float64(0.18013468013468012), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "\n",
      "Compiled modules for significant speedup can not be used!\n",
      "https://pymoo.org/installation.html#installation\n",
      "\n",
      "To disable this warning:\n",
      "from pymoo.config import Config\n",
      "Config.warnings['not_compiled'] = False\n",
      "\n",
      "Dominated Hypervolume: 0.650390625 for Pareto front [[0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 1 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 2, evaluate 3 individuals\n",
      "Running 5-fold CV for individual: 4 total layers, 4 nodes per hidden layer, gs: ([1, 2, 3, 4, 5], [[[7, 0, 6], 0]])\n",
      "Stop early: 0.6670789778232574 < 0.6671033203601837\n",
      "Fold 1/5 | trained for 31 epochs | stopped early: True | metrics: {'loss': 0.6502460837364197, 'auc': np.float64(0.5), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6355315119028091 < 0.6355624496936798\n",
      "Fold 2/5 | trained for 132 epochs | stopped early: True | metrics: {'loss': 0.6572782695293427, 'auc': np.float64(0.6488391376451077), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6302542239427567 < 0.630347341299057\n",
      "Fold 3/5 | trained for 31 epochs | stopped early: True | metrics: {'loss': 0.6314459443092346, 'auc': np.float64(0.5283582089552239), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6550063580274582 < 0.6553322970867157\n",
      "Fold 4/5 | trained for 45 epochs | stopped early: True | metrics: {'loss': 0.6643014550209045, 'auc': np.float64(0.303030303030303), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Stop early: 0.6333595782518386 < 0.6335134208202362\n",
      "Fold 5/5 | trained for 103 epochs | stopped early: True | metrics: {'loss': 0.6242800951004028, 'auc': np.float64(0.7037037037037036), 'nf': 0.375, 'ni': 0.10714285714285714, 'nnm': 0.375}\n",
      "Running 5-fold CV for individual: 4 total layers, 3 nodes per hidden layer, gs: ([0, 2, 4, 6], [[[3], 0], [[5, 7], 1], [[1], 1]])\n",
      "Stop early: 0.6665231078863144 < 0.6674520671367645\n",
      "Fold 1/5 | trained for 45 epochs | stopped early: True | metrics: {'loss': 0.7248427271842957, 'auc': np.float64(0.3258706467661691), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Stop early: 0.5680872589349747 < 0.571225643157959\n",
      "Fold 2/5 | trained for 123 epochs | stopped early: True | metrics: {'loss': 0.6222447156906128, 'auc': np.float64(0.7189054726368159), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Stop early: 0.6511183440685272 < 0.6560734808444977\n",
      "Fold 3/5 | trained for 17 epochs | stopped early: True | metrics: {'loss': 0.6637389361858368, 'auc': np.float64(0.35735607675906184), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Stop early: 0.6474755227565765 < 0.647913247346878\n",
      "Fold 4/5 | trained for 137 epochs | stopped early: True | metrics: {'loss': 0.6615124344825745, 'auc': np.float64(0.5959595959595959), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Stop early: 0.6934275150299072 < 0.6949987709522247\n",
      "Fold 5/5 | trained for 37 epochs | stopped early: True | metrics: {'loss': 0.66753289103508, 'auc': np.float64(0.2596801346801346), 'nf': 0.5, 'ni': 0.03571428571428571, 'nnm': 0.125}\n",
      "Running 5-fold CV for individual: 3 total layers, 8 nodes per hidden layer, gs: ([3, 0, 2, 4, 6, 7], [[[5], 1], [[1], 1]])\n",
      "Stop early: 0.6042146682739258 < 0.606709748506546\n",
      "Fold 1/5 | trained for 24 epochs | stopped early: True | metrics: {'loss': 0.675115555524826, 'auc': np.float64(0.6115257048092868), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6566616982221604 < 0.6597382128238678\n",
      "Fold 2/5 | trained for 13 epochs | stopped early: True | metrics: {'loss': 0.6520723104476929, 'auc': np.float64(0.5259121061359867), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6194484144449234 < 0.6242878437042236\n",
      "Fold 3/5 | trained for 17 epochs | stopped early: True | metrics: {'loss': 0.6662474274635315, 'auc': np.float64(0.5673773987206823), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.659184655547142 < 0.6624006032943726\n",
      "Fold 4/5 | trained for 53 epochs | stopped early: True | metrics: {'loss': 0.6115367412567139, 'auc': np.float64(0.7091750841750842), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6632530212402343 < 0.6663735806941986\n",
      "Fold 5/5 | trained for 17 epochs | stopped early: True | metrics: {'loss': 0.7784964442253113, 'auc': np.float64(0.57996632996633), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Dominated Hypervolume: 0.650390625 for Pareto front [[0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 2 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 3, evaluate 3 individuals\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6455769091844559 < 0.6456077992916107\n",
      "Fold 1/5 | trained for 45 epochs | stopped early: True | metrics: {'loss': 0.6484746038913727, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6682890027761459 < 0.6719614267349243\n",
      "Fold 2/5 | trained for 10 epochs | stopped early: True | metrics: {'loss': 0.6536803245544434, 'auc': np.float64(0.8061774461028193), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6549986928701401 < 0.6550191640853882\n",
      "Fold 3/5 | trained for 69 epochs | stopped early: True | metrics: {'loss': 0.6396094858646393, 'auc': np.float64(0.8049040511727079), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6533886849880218 < 0.6538743376731873\n",
      "Fold 4/5 | trained for 14 epochs | stopped early: True | metrics: {'loss': 0.6700663268566132, 'auc': np.float64(0.25673400673400676), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6314703702926636 < 0.6319828033447266\n",
      "Fold 5/5 | trained for 119 epochs | stopped early: True | metrics: {'loss': 0.6053270101547241, 'auc': np.float64(0.798611111111111), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([2, 3, 4, 5, 6, 7], [[[1, 0], 1]])\n",
      "Stop early: 0.650714311003685 < 0.6531549096107483\n",
      "Fold 1/5 | trained for 24 epochs | stopped early: True | metrics: {'loss': 0.6373552680015564, 'auc': np.float64(0.7373548922056384), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6653566777706146 < 0.6654636561870575\n",
      "Fold 2/5 | trained for 62 epochs | stopped early: True | metrics: {'loss': 0.6554093062877655, 'auc': np.float64(0.18387230514096187), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6676138520240784 < 0.671132504940033\n",
      "Fold 3/5 | trained for 40 epochs | stopped early: True | metrics: {'loss': 0.6500212550163269, 'auc': np.float64(0.7707889125799572), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6939092308282853 < 0.6953284442424774\n",
      "Fold 4/5 | trained for 23 epochs | stopped early: True | metrics: {'loss': 0.6901990175247192, 'auc': np.float64(0.21527777777777776), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Stop early: 0.6017397403717041 < 0.6031236052513123\n",
      "Fold 5/5 | trained for 125 epochs | stopped early: True | metrics: {'loss': 0.634476900100708, 'auc': np.float64(0.7013888888888888), 'nf': 0.25, 'ni': 0.03571428571428571, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 3 total layers, 8 nodes per hidden layer, gs: ([3, 0, 2, 4, 6, 7], [[[5], 1], [[1], 1]])\n",
      "Stop early: 0.6745073467493057 < 0.6843325197696686\n",
      "Fold 1/5 | trained for 24 epochs | stopped early: True | metrics: {'loss': 0.6864882707595825, 'auc': np.float64(0.1627280265339967), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6014685571193695 < 0.6035919785499573\n",
      "Fold 2/5 | trained for 11 epochs | stopped early: True | metrics: {'loss': 0.6600123643875122, 'auc': np.float64(0.6061359867330016), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6606815695762634 < 0.6635783314704895\n",
      "Fold 3/5 | trained for 38 epochs | stopped early: True | metrics: {'loss': 0.6752661466598511, 'auc': np.float64(0.5914712153518124), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6246176511049271 < 0.6255127191543579\n",
      "Fold 4/5 | trained for 21 epochs | stopped early: True | metrics: {'loss': 0.6534059345722198, 'auc': np.float64(0.6007996632996633), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6592660754919052 < 0.6604223847389221\n",
      "Fold 5/5 | trained for 60 epochs | stopped early: True | metrics: {'loss': 0.6650441586971283, 'auc': np.float64(0.41414141414141414), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Dominated Hypervolume: 0.650390625 for Pareto front [[0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 3 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 4, evaluate 3 individuals\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6670891225337983 < 0.6671853363513947\n",
      "Fold 1/5 | trained for 10 epochs | stopped early: True | metrics: {'loss': 0.6598014235496521, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6329627186059952 < 0.6330496966838837\n",
      "Fold 2/5 | trained for 94 epochs | stopped early: True | metrics: {'loss': 0.6482867300510406, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6069511264562607 < 0.6070953607559204\n",
      "Fold 3/5 | trained for 25 epochs | stopped early: True | metrics: {'loss': 0.6361885666847229, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6706411302089691 < 0.6709070801734924\n",
      "Fold 4/5 | trained for 28 epochs | stopped early: True | metrics: {'loss': 0.6870811581611633, 'auc': np.float64(0.20138888888888887), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6456744462251663 < 0.6456943154335022\n",
      "Fold 5/5 | trained for 95 epochs | stopped early: True | metrics: {'loss': 0.6481796205043793, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6407856047153473 < 0.6412855684757233\n",
      "Fold 1/5 | trained for 76 epochs | stopped early: True | metrics: {'loss': 0.629869133234024, 'auc': np.float64(0.7794361525704808), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6845555365085602 < 0.6850515007972717\n",
      "Fold 2/5 | trained for 28 epochs | stopped early: True | metrics: {'loss': 0.6892307996749878, 'auc': np.float64(0.29498341625207297), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6617326706647872 < 0.6631431579589844\n",
      "Fold 3/5 | trained for 122 epochs | stopped early: True | metrics: {'loss': 0.6399866938591003, 'auc': np.float64(0.8010660980810234), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.66148242354393 < 0.6617611348628998\n",
      "Fold 4/5 | trained for 31 epochs | stopped early: True | metrics: {'loss': 0.6425561904907227, 'auc': np.float64(0.8169191919191919), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6898237287998199 < 0.6920709908008575\n",
      "Fold 5/5 | trained for 21 epochs | stopped early: True | metrics: {'loss': 0.6979460716247559, 'auc': np.float64(0.16603535353535354), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 3 total layers, 7 nodes per hidden layer, gs: ([3, 0, 2, 4, 6, 7], [[[5], 1], [[1], 1]])\n",
      "Stop early: 0.6680505961179733 < 0.6690424680709839\n",
      "Fold 1/5 | trained for 52 epochs | stopped early: True | metrics: {'loss': 0.6714638471603394, 'auc': np.float64(0.17537313432835824), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6200129866600037 < 0.6220574975013733\n",
      "Fold 2/5 | trained for 91 epochs | stopped early: True | metrics: {'loss': 0.6532430350780487, 'auc': np.float64(0.5866500829187395), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6367710024118424 < 0.6382010579109192\n",
      "Fold 3/5 | trained for 42 epochs | stopped early: True | metrics: {'loss': 0.6871896684169769, 'auc': np.float64(0.4780383795309169), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.7027238994836807 < 0.7274596691131592\n",
      "Fold 4/5 | trained for 24 epochs | stopped early: True | metrics: {'loss': 0.6845383048057556, 'auc': np.float64(0.3678451178451178), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6463768422603607 < 0.6483200192451477\n",
      "Fold 5/5 | trained for 16 epochs | stopped early: True | metrics: {'loss': 0.664020299911499, 'auc': np.float64(0.5391414141414141), 'nf': 0.25, 'ni': 0.0, 'nnm': 0.0}\n",
      "Dominated Hypervolume: 0.650390625 for Pareto front [[0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 4 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 5, evaluate 3 individuals\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6988694578409195 < 0.6991687119007111\n",
      "Fold 1/5 | trained for 14 epochs | stopped early: True | metrics: {'loss': 0.6739048659801483, 'auc': np.float64(0.1857379767827529), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.7149814665317535 < 0.7166397273540497\n",
      "Fold 2/5 | trained for 19 epochs | stopped early: True | metrics: {'loss': 0.6828087270259857, 'auc': np.float64(0.21683250414593697), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.5975633919239044 < 0.5975952744483948\n",
      "Fold 3/5 | trained for 235 epochs | stopped early: True | metrics: {'loss': 0.599588543176651, 'auc': np.float64(0.8132196162046907), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6868430852890015 < 0.6881822347640991\n",
      "Fold 4/5 | trained for 33 epochs | stopped early: True | metrics: {'loss': 0.6833943724632263, 'auc': np.float64(0.2436868686868687), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.5376345485448837 < 0.5403997153043747\n",
      "Fold 5/5 | trained for 122 epochs | stopped early: True | metrics: {'loss': 0.5708740055561066, 'auc': np.float64(0.7771464646464646), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.5934767723083496 < 0.59988933801651\n",
      "Fold 1/5 | trained for 88 epochs | stopped early: True | metrics: {'loss': 0.6046095192432404, 'auc': np.float64(0.788971807628524), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6270077675580978 < 0.6297547817230225\n",
      "Fold 2/5 | trained for 10 epochs | stopped early: True | metrics: {'loss': 0.6324756145477295, 'auc': np.float64(0.8184079601990051), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6745410770177841 < 0.6746640205383301\n",
      "Fold 3/5 | trained for 37 epochs | stopped early: True | metrics: {'loss': 0.6441537439823151, 'auc': np.float64(0.1211087420042644), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6569799333810806 < 0.6569907069206238\n",
      "Fold 4/5 | trained for 107 epochs | stopped early: True | metrics: {'loss': 0.6542428433895111, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6730054676532745 < 0.6736543476581573\n",
      "Fold 5/5 | trained for 21 epochs | stopped early: True | metrics: {'loss': 0.6573218703269958, 'auc': np.float64(0.7154882154882155), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.7014291971921921 < 0.7028894126415253\n",
      "Fold 1/5 | trained for 10 epochs | stopped early: True | metrics: {'loss': 0.6746565997600555, 'auc': np.float64(0.2796434494195688), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6322064638137818 < 0.6323391199111938\n",
      "Fold 2/5 | trained for 222 epochs | stopped early: True | metrics: {'loss': 0.6483841836452484, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.54490946829319 < 0.5449610650539398\n",
      "Fold 3/5 | trained for 190 epochs | stopped early: True | metrics: {'loss': 0.5693941414356232, 'auc': np.float64(0.7524520255863542), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6681537389755249 < 0.6684191226959229\n",
      "Fold 4/5 | trained for 83 epochs | stopped early: True | metrics: {'loss': 0.6542372703552246, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.5811276793479919 < 0.5815786719322205\n",
      "Fold 5/5 | trained for 323 epochs | stopped early: True | metrics: {'loss': 0.5852387845516205, 'auc': np.float64(0.8539562289562289), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Dominated Hypervolume: 0.650390625 for Pareto front [[0.34960938 0.         0.         0.        ]]\n",
      "Autosaving generation 5 to export/diabetes\n",
      "Saved population + offspring to file\n",
      "Generation 6, evaluate 3 individuals\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6741594642400741 < 0.6743846535682678\n",
      "Fold 1/5 | trained for 21 epochs | stopped early: True | metrics: {'loss': 0.7010867297649384, 'auc': np.float64(0.1981757877280265), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6754726260900498 < 0.6754793524742126\n",
      "Fold 2/5 | trained for 220 epochs | stopped early: True | metrics: {'loss': 0.6559982597827911, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6651645630598069 < 0.6652973592281342\n",
      "Fold 3/5 | trained for 27 epochs | stopped early: True | metrics: {'loss': 0.6604182124137878, 'auc': np.float64(0.26972281449893387), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6179006606340408 < 0.6189608573913574\n",
      "Fold 4/5 | trained for 544 epochs | stopped early: True | metrics: {'loss': 0.6179451048374176, 'auc': np.float64(0.7672558922558922), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.645276454091072 < 0.6452777683734894\n",
      "Fold 5/5 | trained for 337 epochs | stopped early: True | metrics: {'loss': 0.6446992754936218, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Running 5-fold CV for individual: 5 total layers, 3 nodes per hidden layer, gs: ([0, 2, 3, 4, 5, 6, 7], [[[1], 1]])\n",
      "Stop early: 0.6463231652975082 < 0.6463291347026825\n",
      "Fold 1/5 | trained for 153 epochs | stopped early: True | metrics: {'loss': 0.6379538476467133, 'auc': np.float64(0.2524875621890547), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6527545422315597 < 0.653519332408905\n",
      "Fold 2/5 | trained for 29 epochs | stopped early: True | metrics: {'loss': 0.6686883270740509, 'auc': np.float64(0.21393034825870644), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n",
      "Stop early: 0.6569691717624664 < 0.6569709181785583\n",
      "Fold 3/5 | trained for 80 epochs | stopped early: True | metrics: {'loss': 0.629242479801178, 'auc': np.float64(0.5), 'nf': 0.125, 'ni': 0.0, 'nnm': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     22\u001b[0m eagga \u001b[39m=\u001b[39m EAGGA(\n\u001b[0;32m     23\u001b[0m     oml_dataset\u001b[39m=\u001b[39moml_dataset,\n\u001b[0;32m     24\u001b[0m     class_positive\u001b[39m=\u001b[39mclass_positive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     file_path\u001b[39m=\u001b[39mfile_path\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39m#eagga.load_population(6)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m eagga\u001b[39m.\u001b[39;49mrun_eagga()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:587\u001b[0m, in \u001b[0;36mrun_eagga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[39mwhile\u001b[39;00m(datetime\u001b[39m.\u001b[39mnow() \u001b[39m<\u001b[39m time_start \u001b[39m+\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecs_total)):\n\u001b[0;32m    585\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGeneration \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, evaluate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring)\u001b[39m}\u001b[39;00m\u001b[39m individuals\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 587\u001b[0m     \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffspring:\n\u001b[0;32m    588\u001b[0m         individual[\u001b[39m'\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_cv(individual)\n\u001b[0;32m    589\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation\u001b[39m.\u001b[39mappend(individual)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:684\u001b[0m, in \u001b[0;36mrun_cv\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\classes.py:723\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, optimizer, loss_fn, model, dataset_train, dataset_stop_early)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    230\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m cast(Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m], group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    232\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    233\u001b[0m         group,\n\u001b[0;32m    234\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m         state_steps,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[1;32m--> 243\u001b[0m     adamw(\n\u001b[0;32m    244\u001b[0m         params_with_grad,\n\u001b[0;32m    245\u001b[0m         grads,\n\u001b[0;32m    246\u001b[0m         exp_avgs,\n\u001b[0;32m    247\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    248\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    249\u001b[0m         state_steps,\n\u001b[0;32m    250\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    251\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    252\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    253\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    254\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    255\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    256\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    257\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    258\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    259\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    260\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    261\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    262\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    263\u001b[0m         has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m disabled_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 875\u001b[0m func(\n\u001b[0;32m    876\u001b[0m     params,\n\u001b[0;32m    877\u001b[0m     grads,\n\u001b[0;32m    878\u001b[0m     exp_avgs,\n\u001b[0;32m    879\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    880\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    881\u001b[0m     state_steps,\n\u001b[0;32m    882\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    883\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    884\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    885\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    886\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    887\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    888\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    889\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    890\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    891\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    892\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[0;32m    893\u001b[0m     has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[0;32m    894\u001b[0m )\n",
      "File \u001b[1;32mf:\\workplace_github\\ws2425-tab-ml\\code\\.venv\\Lib\\site-packages\\torch\\optim\\adamw.py:425\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    422\u001b[0m     device_beta1 \u001b[39m=\u001b[39m beta1\n\u001b[0;32m    424\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m exp_avg\u001b[39m.\u001b[39;49mlerp_(grad, \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m device_beta1)\n\u001b[0;32m    426\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    428\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps = {\n",
    "    'total_layers': (3, 10),\n",
    "    'nodes_per_hidden_layer': (3, 20),\n",
    "    'mu': 15,  # TODO: 100\n",
    "    'lambda': 5,  # TODO: 10\n",
    "    'holdout_train_size': 2/3,\n",
    "    'cv_k': 5\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "patience = 10\n",
    "\n",
    "secs_per_fold = 30\n",
    "secs_total = 20 * 60\n",
    "\n",
    "for (oml_dataset, class_positive) in zip(oml_datasets[:1], positive_classes[:1]):  # TODO: remove [:1]\n",
    "    name = oml_dataset.name\n",
    "    print(f'Dataset {name}')\n",
    "\n",
    "    file_path = os.path.join('export', name)\n",
    "    \n",
    "    eagga = EAGGA(\n",
    "        oml_dataset=oml_dataset,\n",
    "        class_positive=class_positive,\n",
    "        hps=hps,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        secs_per_fold=secs_per_fold,\n",
    "        secs_total=secs_total,\n",
    "        file_path=file_path\n",
    "    )\n",
    "    #eagga.load_population(6)\n",
    "    eagga.run_eagga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
